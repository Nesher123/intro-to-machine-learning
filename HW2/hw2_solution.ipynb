{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "hw2_204502926_204945323.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-6bd0516e7cb654f5",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "tV58SzIACI9i"
      },
      "source": [
        "# Exercise 2: Decision Trees\n",
        "\n",
        "In this assignment you will implement a Decision Tree algorithm as learned in class.\n",
        "\n",
        "## Read the following instructions carefully:\n",
        "\n",
        "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
        "1. Submission includes this notebook only with the exercise number and your ID as the filename. For example: `hw2_123456789_987654321.ipynb` if you submitted in pairs and `hw2_123456789.ipynb` if you submitted the exercise alone.\n",
        "1. Write **efficient vectorized** code whenever possible. Some calculations in this exercise take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deduction.\n",
        "1. You are responsible for the correctness of your code and should add as many tests as you see fit. Tests will not be graded nor checked.\n",
        "1. Write your functions in this notebook only. **Do not create Python modules and import them**.\n",
        "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only. **Do not import anything else.**\n",
        "1. Your code must run without errors. Make sure your `numpy` version is at least 1.15.4 and that you are using at least python 3.6. Changes of the configuration we provided are at your own risk. Any code that cannot run will not be graded.\n",
        "1. Write your own code. Cheating will not be tolerated.\n",
        "1. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support). Answers that will be written in commented code blocks will not be checked.\n",
        "\n",
        "## In this exercise you will perform the following:\n",
        "1. Practice OOP in python.\n",
        "2. Implement two impurity measures: Gini and Entropy.\n",
        "3. Construct a decision tree algorithm.\n",
        "4. Prune the tree to achieve better results.\n",
        "5. Visualize your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ha4C86rCI9k"
      },
      "source": [
        "# I have read and understood the instructions: 204502926, 204945323"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-ed9fe7b1026e33cb",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "BbDOlJkdCI9k"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make matplotlib figures appear inline in the notebook\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-c6ac605270c2b091",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "A3KZOAmVCI9l"
      },
      "source": [
        "## Warmup - OOP in python\n",
        "\n",
        "Our desicion tree will be implemented using a dedicated python class. Python classes are very similar to classes in Java.\n",
        "\n",
        "\n",
        "You can use the following [site](https://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/) to learn about classes in python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6sIVmH0CI9l"
      },
      "source": [
        "class Node(object):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.children = []\n",
        "\n",
        "    def add_child(self, node):\n",
        "        self.children.append(node)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFVYFWdyCI9m",
        "outputId": "5fe42463-711e-40ec-a401-83e34f4982b4"
      },
      "source": [
        "n = Node(5)\n",
        "p = Node(6)\n",
        "q = Node(7)\n",
        "n.add_child(p)\n",
        "n.add_child(q)\n",
        "n.children"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.Node at 0x7fd2bf5a9a10>, <__main__.Node at 0x7fd2bf5a9a90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-2f1ceb251c649b62",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "4jqGtE_SCI9m"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "For the following exercise, we will use a dataset containing mushroom data `agaricus-lepiota.csv`. \n",
        "\n",
        "This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family. Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous\n",
        "one (=there are only two classes **edible** and **poisonous**). \n",
        "    \n",
        "The dataset contains 8124 observations with 22 features:\n",
        "1. cap-shape: bell=b,conical=c,convex=x,flat=f,knobbed=k,sunken=s\n",
        "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
        "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "4. bruises: bruises=t,no=f\n",
        "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
        "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
        "7. gill-spacing: close=c,crowded=w,distant=d\n",
        "8. gill-size: broad=b,narrow=n\n",
        "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g,green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y\n",
        "10. stalk-shape: enlarging=e,tapering=t\n",
        "11. stalk-root: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r\n",
        "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
        "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y\n",
        "16. veil-type: partial=p,universal=u\n",
        "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
        "18. ring-number: none=n,one=o,two=t\n",
        "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z\n",
        "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y\n",
        "21. population: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y\n",
        "22. habitat: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d\n",
        "\n",
        "First, we will read and explore the data using pandas and the `.read_csv` method. Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d79cb4542926ad3f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "cj3yq_nkCI9n"
      },
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('agaricus-lepiota.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blxZRpOuCI9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "6d3c3c44-8fbb-4460-fad7-6f4c1ec5f7b1"
      },
      "source": [
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>t</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8119</th>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8120</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>v</td>\n",
              "      <td>l</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8121</th>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>b</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "      <td>e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8122</th>\n",
              "      <td>k</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>y</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>b</td>\n",
              "      <td>t</td>\n",
              "      <td>s</td>\n",
              "      <td>k</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>l</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8123</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>y</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>o</td>\n",
              "      <td>c</td>\n",
              "      <td>l</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8124 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cap-shape cap-surface cap-color  ... population habitat class\n",
              "0            x           s         n  ...          s       u     p\n",
              "1            x           s         y  ...          n       g     e\n",
              "2            b           s         w  ...          n       m     e\n",
              "3            x           y         w  ...          s       u     p\n",
              "4            x           s         g  ...          a       g     e\n",
              "...        ...         ...       ...  ...        ...     ...   ...\n",
              "8119         k           s         n  ...          c       l     e\n",
              "8120         x           s         n  ...          v       l     e\n",
              "8121         f           s         n  ...          c       l     e\n",
              "8122         k           y         n  ...          v       l     p\n",
              "8123         x           s         n  ...          c       l     p\n",
              "\n",
              "[8124 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW26HjJNCI9n"
      },
      "source": [
        "One of the advantages of the Decision Tree algorithm is that almost no preprocessing is required. However, finding missing values is always required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGDubwAACI9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d899f7-af78-4e1b-a880-e0834fdce546"
      },
      "source": [
        "#############################################################################\n",
        "# TODO: Find the columns with missing values and remove them from the data.#\n",
        "#############################################################################\n",
        "print(f'{data.isnull().values.any()}\\n') # if any\n",
        "print(f'{data.isnull().sum()}\\n') # missing values' sum per column\n",
        "print(f'{data.isnull().sum().sum()}') # overall missing values' sum\n",
        "# no missing values in data\n",
        "\n",
        "data = data.dropna()\n",
        "#############################################################################\n",
        "#                             END OF YOUR CODE                              #\n",
        "#############################################################################"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "\n",
            "cap-shape                   0\n",
            "cap-surface                 0\n",
            "cap-color                   0\n",
            "bruises                     0\n",
            "odor                        0\n",
            "gill-attachment             0\n",
            "gill-spacing                0\n",
            "gill-size                   0\n",
            "gill-color                  0\n",
            "stalk-shape                 0\n",
            "stalk-surface-above-ring    0\n",
            "stalk-surface-below-ring    0\n",
            "stalk-color-above-ring      0\n",
            "stalk-color-below-ring      0\n",
            "veil-type                   0\n",
            "veil-color                  0\n",
            "ring-number                 0\n",
            "ring-type                   0\n",
            "spore-print-color           0\n",
            "population                  0\n",
            "habitat                     0\n",
            "class                       0\n",
            "dtype: int64\n",
            "\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEwZtYzPCI9o"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1_74iEcCI9o"
      },
      "source": [
        "We will split the dataset to `Training` and `Testing` datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0NsUYrkCI9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5f01e6-935f-4e4d-e371-727657332d4d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Making sure the last column will hold the labels\n",
        "X, y = data.drop('class', axis=1), data['class']\n",
        "X = np.column_stack([X,y])\n",
        "# split dataset using random_state to get the same split each time\n",
        "X_train, X_test = train_test_split(X, random_state=99)\n",
        "\n",
        "print(\"Training dataset shape: \", X_train.shape)\n",
        "print(\"Testing dataset shape: \", X_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset shape:  (6093, 22)\n",
            "Testing dataset shape:  (2031, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwaghz0zCI9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e112002f-8af8-4075-b779-614280937e9c"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8124,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x5ekVHTTaYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00d673e-ffaa-45fa-ee2f-a6bc4a442b30"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['x', 's', 'y', ..., 'n', 'g', 'e'],\n",
              "       ['k', 'y', 'e', ..., 'v', 'l', 'e'],\n",
              "       ['f', 'y', 'n', ..., 'v', 'p', 'p'],\n",
              "       ...,\n",
              "       ['x', 'y', 'n', ..., 'v', 'l', 'p'],\n",
              "       ['k', 's', 'e', ..., 'v', 'l', 'e'],\n",
              "       ['f', 'y', 'g', ..., 'y', 'p', 'p']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy67On9AaLWZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fd7b0191f3f1e897",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "zybGnJaNCI9p"
      },
      "source": [
        "## Impurity Measures\n",
        "\n",
        "Impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. Implement the functions `calc_gini` and `calc_entropy`. You are encouraged to test your implementation (10 points)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psN9oQ9sWsZ0"
      },
      "source": [
        "# Helper functions for this part\n",
        "\n",
        "def get_probabilities_dict(array):\n",
        "    '''\n",
        "    Returns a dictionary with the probabilities for each of the given column-array's unique keys.\n",
        "    (ex.: {'yes': 0.51, 'no': 0.49})\n",
        "    '''\n",
        "    unique, counts = np.unique(array, return_counts=True)\n",
        "    return dict(zip(unique, counts/sum(counts)))\n",
        "\n",
        "\n",
        "def calculate_gini_impurity_from_dict(probabilities_dict):\n",
        "    return 1 - sum(np.square(list(probabilities_dict.values())))\n",
        "\n",
        "\n",
        "def calculate_entropy_from_dict(probabilities_dict):\n",
        "    return -sum(p * np.log2(p) for p in list(probabilities_dict.values()))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqtLW8DbCI9p"
      },
      "source": [
        "def calc_gini(data):\n",
        "    \"\"\"\n",
        "    Calculate gini impurity measure of a dataset.\n",
        " \n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        " \n",
        "    Returns the gini impurity.\n",
        "    \"\"\"\n",
        "    gini = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    labels = data[:,-1] # the last column holds the labels\n",
        "    probabilities = get_probabilities_dict(labels)\n",
        "    gini = calculate_gini_impurity_from_dict(probabilities)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return gini"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euglt_5yCI9q"
      },
      "source": [
        "def calc_entropy(data):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a dataset.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "\n",
        "    Returns the entropy of the dataset.\n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    labels = data[:,-1] # the last column holds the labels\n",
        "    probabilities = get_probabilities_dict(labels)\n",
        "    entropy = calculate_entropy_from_dict(probabilities)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return entropy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7EiAc1_FCI9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8206725-97a1-4d06-a03b-b6cf72905f80"
      },
      "source": [
        "##### Your Tests Here #####\n",
        "calc_gini(X), calc_entropy(X)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4995636322379775, 0.9993703627906085)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8c3R2GDaGNY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeq9yuAdCI9q"
      },
      "source": [
        "## Goodness of Split\n",
        "\n",
        "Given a feature the Goodnees of Split measures the reduction in the impurity if we split the data according to the feature.\n",
        "$$\n",
        "\\Delta\\varphi(S, A) = \\varphi(S) - \\sum_{v\\in Values(A)} \\frac{|S_v|}{|S|}\\varphi(S_v)\n",
        "$$\n",
        "\n",
        "In our implementation the goodness_of_split function will return either the Goodness of Split or the Gain Ratio as learned in class. You'll control the return value with the `gain_ratio` parameter. If this parameter will set to False (the default value) it will return the regular Goodness of Split. If it will set to True it will return the Gain Ratio.\n",
        "$$\n",
        "GainRatio(S,A)=\\frac{InformationGain(S,A)}{SplitInformation(S,A)}\n",
        "$$\n",
        "Where:\n",
        "$$\n",
        "InformationGain(S,A)=Goodness\\ of\\ Split\\ calculated\\ with\\ Entropy\\ as\\ the\\ Impurity\\ function \\\\\n",
        "SplitInformation(S,A)=- \\sum_{a\\in A} \\frac{|S_a|}{|S|}\\log\\frac{|S_a|}{|S|}\n",
        "$$\n",
        "NOTE: you can add more parameters to the function and you can also add more returning variables (The given parameters and the given returning variable should not be touch). (10 Points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zycqxxqeLNS"
      },
      "source": [
        "# Helper functions for this part\n",
        "\n",
        "def split(data, value, feature):\n",
        "    filtered_array = data[data[:,feature] == value][:,-1]\n",
        "    return get_probabilities_dict(filtered_array)\n",
        "\n",
        "\n",
        "def calculate_impurity_from_dict(split_data, impurity_criterion):\n",
        "    if impurity_criterion == 'gini':\n",
        "        return calculate_gini_impurity_from_dict(split_data)\n",
        "    else:\n",
        "        return calculate_entropy_from_dict(split_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuESgCcICI9r"
      },
      "source": [
        "def goodness_of_split(data, feature, impurity_func, gain_ratio=False):\n",
        "    \"\"\"\n",
        "    Calculate the goodness of split of a dataset given a feature and impurity function.\n",
        "\n",
        "    Input:\n",
        "    - data: any dataset where the last column holds the labels.\n",
        "    - feature: the feature index.\n",
        "    - impurity_func: a function that calculates the impurity.\n",
        "    - gain_ratio: goodness of split or gain ratio flag.\n",
        "\n",
        "    Returns the goodness of split (or the Gain Ratio).\n",
        "    \"\"\"\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    if impurity_func == calc_entropy or gain_ratio == True:\n",
        "        impurity_criterion = 'entropy'\n",
        "        impurity = calc_entropy(data)\n",
        "    else:\n",
        "        impurity_criterion = 'gini'\n",
        "        impurity = calc_gini(data)\n",
        "\n",
        "    gain = 0\n",
        "    len_of_data = data.shape[0]\n",
        "\n",
        "    feature_values = np.unique(data[:,feature])\n",
        "    \n",
        "    for value in feature_values:\n",
        "        number_of_instances = len(data[data[:,feature] == value])\n",
        "        split_data = split(data, value, feature)\n",
        "        # print(split_data, number_of_instances, len_of_data)\n",
        "        gain += (number_of_instances / len_of_data) * calculate_impurity_from_dict(split_data, impurity_criterion)\n",
        "\n",
        "    if gain_ratio == False:\n",
        "        # calculate the impurity of the node (parent) using the impurity_func passed as a parameter (gini or entorpy) and substract the weighted impurity (gini or entropy) of the children.\n",
        "        goodness = impurity - gain\n",
        "    else:\n",
        "        # calculate the information gain specifically with entropy as the impurity function, and divide it by split information.\n",
        "        information_gain = impurity # just for naming conventions in the formula\n",
        "\n",
        "        fractions = np.unique(data[:, feature], return_counts=True)[1] / data.shape[0]\n",
        "        split_information = -(np.log2(fractions) * fractions).sum()\n",
        "        gain_ratio_value = information_gain / split_information\n",
        "        goodness = gain_ratio_value\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return goodness"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1GR5wvLqJiH"
      },
      "source": [
        "# ##### TESTS #####\n",
        "# tennis_data = {\n",
        "#     'day' : [1,2,3,4,5,6,7,8,9,10,11,12,13,14],\n",
        "#     'outlook' : ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast', 'rain'],\n",
        "#     'temperature' : ['hot', 'hot', 'hot', 'mild', 'cool', 'cool', 'cool', 'mild', 'cool', 'mild', 'mild', 'mild', 'hot', 'mild'],\n",
        "#     'humidity' : ['high', 'high', 'high', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'normal', 'normal', 'high', 'normal', 'high'],\n",
        "#     'wind' : ['weak', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'weak', 'weak', 'strong', 'strong', 'weak', 'strong'],\n",
        "#     'playsTennis' : ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
        "# }\n",
        "\n",
        "# tennis_data = pd.DataFrame(tennis_data, columns=tennis_data.keys())\n",
        "# label_column = 'playsTennis'\n",
        "# A, b = tennis_data.drop([label_column], axis=1), tennis_data[label_column]\n",
        "# A = np.column_stack([A,b])\n",
        "\n",
        "# print(A)\n",
        "# calc_gini(A), calc_entropy(A)\n",
        "# feature = 0 # 0 is 'day'\n",
        "# goodness_of_split(A, feature, calc_entropy, False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUGl0BOOrCv0"
      },
      "source": [
        "def get_goodness_of_split_for_all_features(data, array_of_feature_indices, impurity=calc_gini, gain_ratio=False):\n",
        "    goodness_of_split_dict = dict()\n",
        "\n",
        "    for i in array_of_feature_indices:\n",
        "        goodness_of_split_dict[i] = goodness_of_split(data, i, impurity, gain_ratio)\n",
        "\n",
        "    return goodness_of_split_dict"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYHek1WngM4U"
      },
      "source": [
        "# array_of_feature_indices = np.arange(1,5) # [1,2,3,4] excluding the 'day' & 'label' features\n",
        "# get_goodness_of_split_for_all_features(A, array_of_feature_indices, calc_gini)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNnvuZ-dfHnn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v299Jf3rCI9r"
      },
      "source": [
        "## Building a Decision Tree\n",
        "\n",
        "Use a Python class to construct the decision tree. Your class should support the following functionality:\n",
        "\n",
        "1. Initiating a node for a decision tree. You will need to use several class methods and class attributes and you are free to use them as you see fit. We recommend that every node will hold the feature and value used for the split and its children.\n",
        "2. Your code should support both Gini and Entropy as impurity measures. \n",
        "3. The provided data includes categorical data. In this exercise, when splitting a node create the number of children needed according to the attribute unique values.\n",
        "\n",
        "Complete the class `DecisionNode`. The structure of this class is entirely up to you. \n",
        "\n",
        "Complete the function `build_tree`. This function should get the training dataset and the impurity as inputs, initiate a root for the decision tree and construct the tree according to the procedure you learned in class. (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_IiW9G3ITy"
      },
      "source": [
        "### Chi square table values ###\n",
        "# The first key is the degree of freedom\n",
        "# The second key is the p-value cut-off\n",
        "# The values are the chi-statistic that you need to use in the pruning\n",
        "\n",
        "chi_table = {1: {0.5 : 0.45,\n",
        "                 0.25 : 1.32,\n",
        "                 0.1 : 2.71,\n",
        "                 0.05 : 3.84,\n",
        "                 0.0001 : 100000},\n",
        "             2: {0.5 : 1.39,\n",
        "                 0.25 : 2.77,\n",
        "                 0.1 : 4.60,\n",
        "                 0.05 : 5.99,\n",
        "                 0.0001 : 100000},\n",
        "             3: {0.5 : 2.37,\n",
        "                 0.25 : 4.11,\n",
        "                 0.1 : 6.25,\n",
        "                 0.05 : 7.82,\n",
        "                 0.0001 : 100000},\n",
        "             4: {0.5 : 3.36,\n",
        "                 0.25 : 5.38,\n",
        "                 0.1 : 7.78,\n",
        "                 0.05 : 9.49,\n",
        "                 0.0001 : 100000},\n",
        "             5: {0.5 : 4.35,\n",
        "                 0.25 : 6.63,\n",
        "                 0.1 : 9.24,\n",
        "                 0.05 : 11.07,\n",
        "                 0.0001 : 100000},\n",
        "             6: {0.5 : 5.35,\n",
        "                 0.25 : 7.84,\n",
        "                 0.1 : 10.64,\n",
        "                 0.05 : 12.59,\n",
        "                 0.0001 : 100000},\n",
        "             7: {0.5 : 6.35,\n",
        "                 0.25 : 9.04,\n",
        "                 0.1 : 12.01,\n",
        "                 0.05 : 14.07,\n",
        "                 0.0001 : 100000},\n",
        "             8: {0.5 : 7.34,\n",
        "                 0.25 : 10.22,\n",
        "                 0.1 : 13.36,\n",
        "                 0.05 : 15.51,\n",
        "                 0.0001 : 100000},\n",
        "             9: {0.5 : 8.34,\n",
        "                 0.25 : 11.39,\n",
        "                 0.1 : 14.68,\n",
        "                 0.05 : 16.92,\n",
        "                 0.0001 : 100000},\n",
        "             10: {0.5 : 9.34,\n",
        "                  0.25 : 12.55,\n",
        "                  0.1 : 15.99,\n",
        "                  0.05 : 18.31,\n",
        "                  0.0001 : 100000},\n",
        "             11: {0.5 : 10.34,\n",
        "                  0.25 : 13.7,\n",
        "                  0.1 : 17.27,\n",
        "                  0.05 : 19.68,\n",
        "                  0.0001 : 100000}}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2biBjgHQAfK"
      },
      "source": [
        "def get_subtable(data, node, value):\n",
        "    '''\n",
        "    Returns subtable where it's only the instances of given value\n",
        "    ex.: all instances with outlook == 'sunny'\n",
        "    ''' \n",
        "    return data[data[:,node] == value]\n",
        "\n",
        "\n",
        "def get_frequent_prediction(data):\n",
        "    '''\n",
        "    Returns the most frequent *label* from given data\n",
        "    '''\n",
        "    l = list(data[:,-1]) # -1 is the last column where the label is\n",
        "    frequent = max(set(l), key = l.count)\n",
        "    return frequent\n",
        "\n",
        "\n",
        "def get_chi_square(data, feature):\n",
        "    feature_values = np.unique(data[:, feature])\n",
        "    num_samples = data.shape[0]\n",
        "    class_pos, class_neg = (data[:, -1] == \"p\").sum(), (data[:, -1] == \"e\").sum()\n",
        "    prob_pos, prob_neg = class_pos / num_samples, class_neg / num_samples\n",
        "    chi_stat = 0.0\n",
        "\n",
        "    for value in feature_values:\n",
        "        subset = (data[:, feature] == value)\n",
        "        d = subset.sum()\n",
        "        pos = (subset & (data[:, -1] == \"p\")).sum()\n",
        "        neg = d - pos\n",
        "        E_pos, E_neg = d * prob_pos, d * prob_neg\n",
        "\n",
        "        chi_stat += ((pos - E_pos)**2 / E_pos) + ((neg - E_neg)**2 / E_neg)\n",
        "\n",
        "    return chi_stat"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaRGo2t-CI9r"
      },
      "source": [
        "class DecisionNode:\n",
        "    \"\"\"\n",
        "    This class will hold everything you require to construct a decision tree.\n",
        "    The structure of this class is up to you. However, you need to support basic \n",
        "    functionality as described above. It is highly recommended that you \n",
        "    first read and understand the entire exercise before diving into this class.\n",
        "    \"\"\"\n",
        "    def __init__(self, feature_name, feature, came_from_feature):\n",
        "        self.feature = feature # column index of criteria being tested\n",
        "        self.feature_name = feature_name\n",
        "        self.children = []\n",
        "        self.data = None # holds the relevant data at each node\n",
        "        self.is_leaf = False\n",
        "        self.prediction = None\n",
        "        self.parent = came_from_feature\n",
        "\n",
        "    def add_child(self, node):\n",
        "        self.children.append(node)\n",
        "\n",
        "    def add_data(self, data):\n",
        "        self.data = data\n",
        "        # total number of samples\n",
        "        self.samples = data.shape[0]\n",
        "        # number of occurances of each class\n",
        "        unique, counts = np.unique(data[:, -1], return_counts=True)\n",
        "        self.class_counts = dict(zip(unique, counts))\n",
        "\n",
        "    def get_is_leaf(self):\n",
        "        return self.is_leaf\n",
        "    \n",
        "    def set_is_leaf(self, value):\n",
        "        self.is_leaf = value    \n",
        "    \n",
        "    def get_prediction(self):\n",
        "        return self.prediction\n",
        "\n",
        "    def set_prediction(self, value):\n",
        "        self.prediction = value"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btZ_dLQb3dPS"
      },
      "source": [
        "def build_subtree(data, impurity, parent_feature, gain_ratio=False, chi=1.0, max_depth=1000,\n",
        "                  array_of_feature_indices=None, depth=0, feature_name=''):\n",
        "    goodness_of_split_dict = get_goodness_of_split_for_all_features(data, array_of_feature_indices, impurity)\n",
        "\n",
        "    best_feature = max(goodness_of_split_dict, key=goodness_of_split_dict.get)\n",
        "\n",
        "    node = DecisionNode(feature_name, best_feature, parent_feature)\n",
        "\n",
        "    attValue = np.unique(data[:, best_feature])\n",
        "\n",
        "    deg_of_freedom = len(attValue) - 1\n",
        "    should_prune = False\n",
        "\n",
        "    if chi != 1 and deg_of_freedom > 0:\n",
        "        chi_stat = get_chi_square(data, best_feature)\n",
        "        should_prune = chi_stat <= chi_table[deg_of_freedom][chi]\n",
        "\n",
        "    if all(value == 0 for value in goodness_of_split_dict.values()) or not max_depth or should_prune:\n",
        "        # no gain by splitting anymore or too deep in recursion\n",
        "        frequent = get_frequent_prediction(data)\n",
        "        child_node = DecisionNode(feature_name, None, parent_feature)\n",
        "        child_node.set_is_leaf(True)\n",
        "        child_node.set_prediction(frequent)\n",
        "        child_node.add_data(data)\n",
        "\n",
        "        return child_node\n",
        "\n",
        "    for feature_name in attValue:\n",
        "        subtable = get_subtable(data, best_feature, feature_name)\n",
        "        clValue, counts = np.unique(subtable[:, -1], return_counts=True)\n",
        "        parent_feature = best_feature\n",
        "\n",
        "        if len(counts) == 1 or should_prune:\n",
        "            # stop if the subset is pure\n",
        "            child_node = DecisionNode(feature_name, None, best_feature)\n",
        "            child_node.set_is_leaf(True)\n",
        "            child_node.set_prediction(clValue[0])\n",
        "        else:\n",
        "            child_node = build_subtree(data=subtable, chi=chi, impurity=impurity, gain_ratio=gain_ratio, \n",
        "                                       max_depth=max_depth-1, array_of_feature_indices=array_of_feature_indices, \n",
        "                                       feature_name=feature_name, parent_feature=parent_feature)\n",
        "\n",
        "        child_node.add_data(subtable)\n",
        "        node.add_child(child_node)\n",
        "\n",
        "    return node\n",
        "\n",
        "\n",
        "def build_tree(data, impurity, gain_ratio=False, chi=1.0, max_depth=1000, array_of_feature_indices=None):\n",
        "    \"\"\"\n",
        "    Build a tree using the given impurity measure and training dataset. \n",
        "    You are required to fully grow the tree until all leaves are pure. \n",
        "\n",
        "    Input:\n",
        "    - data: the training dataset.\n",
        "    - impurity: the chosen impurity measure. Notice that you can send a function\n",
        "                as an argument in python.\n",
        "    - gain_ratio: goodness of split or gain ratio flag\n",
        "    - chi: chi square p-value cut off (1 means no pruning)\n",
        "    - max_depth: the allowable depth of the tree\n",
        "\n",
        "    Output: the root node of the tree.\n",
        "    \"\"\"\n",
        "\n",
        "    root = None\n",
        "\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    if len(data) == 1:\n",
        "        return data[0][-1]\n",
        "\n",
        "    if array_of_feature_indices is None:\n",
        "        array_of_feature_indices = np.arange(data.shape[1] - 1)\n",
        "\n",
        "    feature_name = 'ROOT'\n",
        "    parent_feature = -1\n",
        "    root = build_subtree(data=data, impurity=impurity, chi=chi, max_depth=max_depth, gain_ratio=gain_ratio,\n",
        "                         array_of_feature_indices=array_of_feature_indices, feature_name=feature_name,\n",
        "                         parent_feature=parent_feature)\n",
        "    root.add_data(data)\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return root"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA62oiZZ0C-Q"
      },
      "source": [
        "# array_of_feature_indices = np.arange(1, 5)\n",
        "# t = build_tree(data=A, impurity=calc_gini, array_of_feature_indices=array_of_feature_indices)\n",
        "\n",
        "# def get_tree(t):\n",
        "#     print(t.feature_name, t.feature, t.parent)\n",
        "#     print('-')\n",
        "\n",
        "#     for n in t.children:\n",
        "#         print(n.feature_name, n.feature, n.parent)\n",
        "#         print(n.children)\n",
        "#         print('--')\n",
        "\n",
        "#         for a in n.children:\n",
        "#             print(a.children)\n",
        "#             print(a.feature_name, a.feature, a.parent)\n",
        "#             print(a.get_is_leaf())\n",
        "#             print('---')\n",
        "\n",
        "\n",
        "# get_tree(t)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QS3c5bxCI9s"
      },
      "source": [
        "# python supports passing a function as an argument to another function.\n",
        "tree_gini = build_tree(data=X_train, impurity=calc_gini) # gini and goodness of split\n",
        "tree_entropy = build_tree(data=X_train, impurity=calc_entropy) # entropy and goodness of split\n",
        "tree_entropy_gain_ratio = build_tree(data=X_train, impurity=calc_entropy, gain_ratio=True) # entropy and gain ratio"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKOLi03JouvX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1A0p654CI9s"
      },
      "source": [
        "## Tree evaluation\n",
        "\n",
        "Complete the functions `predict` and `calc_accuracy`. (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9_NzVQ3CI9t"
      },
      "source": [
        "def predict(node, instance):\n",
        "    \"\"\"\n",
        "    Predict a given instance using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - root: the root of the decision tree.\n",
        "    - instance: an row vector from the dataset. Note that the last element \n",
        "                of this vector is the label of the instance.\n",
        " \n",
        "    Output: the prediction of the instance.\n",
        "    \"\"\"\n",
        "    pred = None\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    while (node.get_prediction() is None): # OR while (node.is_leaf == False):\n",
        "        split_feature = node.feature\n",
        "        instance_value = instance[split_feature]\n",
        "        \n",
        "        matching_child = [i for i in range(len(node.children)) if node.children[i].feature_name == instance_value]\n",
        "\n",
        "        try:\n",
        "            node = node.children[matching_child[0]]\n",
        "        except:\n",
        "            # current instance has value which does not appear in the tree at this node:\n",
        "            # the training data probably did not have any such values when the tree was build\n",
        "            # so we'll take the majority of predictions at this point and return it for this instance\n",
        "\n",
        "            # it means that len(matching_child) == 0\n",
        "            frequent = get_frequent_prediction(node.data)\n",
        "            return frequent\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return node.get_prediction()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjpe5Pb3CI9t"
      },
      "source": [
        "def calc_accuracy(node, dataset):\n",
        "    \"\"\"\n",
        "    Predict a given dataset using the decision tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        "    - dataset: the dataset on which the accuracy is evaluated\n",
        " \n",
        "    Output: the accuracy of the decision tree on the given dataset (%).\n",
        "    \"\"\"\n",
        "    accuracy = 0\n",
        "    ###########################################################################\n",
        "    # TODO: Implement the function.                                           #\n",
        "    ###########################################################################\n",
        "    total = dataset.shape[0]\n",
        "    hits = 0\n",
        "\n",
        "    for row in range(len(dataset)):\n",
        "        label = dataset[row][-1]\n",
        "        instance = dataset[row]\n",
        "        try:\n",
        "            prediction = predict(node, instance)\n",
        "        except:\n",
        "            print('error on predict')\n",
        "        \n",
        "        if label == prediction:\n",
        "            hits += 1\n",
        "    \n",
        "    accuracy = hits/total\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    return accuracy "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoBmwcFsCI9t"
      },
      "source": [
        "After building the three trees using the training set, you should calculate the accuracy on the test set. For each tree print the training and test accuracy. Select the tree that gave you the best test accuracy. For the rest of the exercise, use that tree (when you asked to build another tree use the same impurity function and same gain_ratio flag). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvmbEJdNCI9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8994e6-2621-4e45-ca9a-9bb61f7f9731"
      },
      "source": [
        "test_set_accuracies = {\n",
        "    tree_gini: calc_accuracy(tree_gini, X_test),\n",
        "    tree_entropy: calc_accuracy(tree_entropy, X_test),\n",
        "    tree_entropy_gain_ratio: calc_accuracy(tree_entropy_gain_ratio, X_test)\n",
        "}\n",
        "\n",
        "print(f'X_train Gini: {calc_accuracy(tree_gini, X_train) * 100}%')\n",
        "print(f'X_test Gini: {test_set_accuracies[tree_gini] * 100}%')\n",
        "\n",
        "print(f'X_train Entropy: {calc_accuracy(tree_entropy, X_train) * 100}%')\n",
        "print(f'X_test Entropy: {test_set_accuracies[tree_entropy] * 100}%')\n",
        "\n",
        "print(f'X_train Entropy_gain_ratio: : {calc_accuracy(tree_entropy_gain_ratio, X_train) * 100}%')\n",
        "print(f'X_test Entropy_gain_ratio: {test_set_accuracies[tree_entropy_gain_ratio] * 100}%')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Gini: 99.24503528639423%\n",
            "X_test Gini: 77.69571639586411%\n",
            "X_train Entropy: 99.40915805022156%\n",
            "X_test Entropy: 78.13884785819793%\n",
            "X_train Entropy_gain_ratio: : 99.40915805022156%\n",
            "X_test Entropy_gain_ratio: 78.13884785819793%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLwnZSna9n0c"
      },
      "source": [
        "best_test_tree = max(test_set_accuracies, key=test_set_accuracies.get)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMnp3XeItcjD",
        "outputId": "f2954476-f84f-41e7-bc1a-7ae85081ce3a"
      },
      "source": [
        "print(max(test_set_accuracies, key=test_set_accuracies.get)) # best_tree is a copy of this tree\n",
        "print(tree_gini)\n",
        "print(tree_entropy)\n",
        "print(tree_entropy_gain_ratio)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<__main__.DecisionNode object at 0x7fd2af948b90>\n",
            "<__main__.DecisionNode object at 0x7fd2bf5a9c90>\n",
            "<__main__.DecisionNode object at 0x7fd2af948b90>\n",
            "<__main__.DecisionNode object at 0x7fd2af6354d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mPEOcvFo_jz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG6PL2smCI9t"
      },
      "source": [
        "## Post pruning\n",
        "\n",
        "Iterate over all nodes in the tree that have at least a single child which is a leaf. For each such node, replace it with its most popular class. Calculate the accuracy on the testing dataset, pick the node that results in the highest testing accuracy and permanently change it in the tree. Repeat this process until you are left with a single node in the tree (the root). Finally, create a plot of the training and testing accuracies as a function of the number of nodes in the tree. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak3HFlwcM-UV"
      },
      "source": [
        "def count_nodes(node):\n",
        "    \"\"\"\n",
        "    Count the number of node in a given tree\n",
        " \n",
        "    Input:\n",
        "    - node: a node in the decision tree.\n",
        " \n",
        "    Output: the number of node in the tree.\n",
        "    \"\"\"\n",
        "    count = 1\n",
        "\n",
        "    # just the classic recursive algorithm of incrementing a counter per visited node\n",
        "    for n in node.children:\n",
        "        count += count_nodes(n)\n",
        "\n",
        "    return count\n",
        "\n",
        "\n",
        "def get_parent_nodes_of_leaves(node):\n",
        "    parent_nodes_of_leaves = []\n",
        "\n",
        "    for n in node.children:\n",
        "        parent_nodes_of_leaves.extend(get_parent_nodes_of_leaves(n))\n",
        "\n",
        "    # for each child, if it is a leaf, add it to the list of parent nodes with leaf \n",
        "    for n in node.children:\n",
        "        if n.get_is_leaf():\n",
        "            parent_nodes_of_leaves.extend([node])\n",
        "            # we need to know there is just at least one leaf\n",
        "            break\n",
        "\n",
        "    return parent_nodes_of_leaves"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJNBw-6ZnETw",
        "outputId": "aaf05255-e502-4e43-aec6-b37cc27dd30c"
      },
      "source": [
        "print(count_nodes(tree_gini))\n",
        "print(count_nodes(tree_entropy))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3231\n",
            "3227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUGXISk3ypBU"
      },
      "source": [
        "# def show_post_pruning_plot(nodes_counts, training_set_post_pruning_accuracies, test_set_post_pruning_accuracies):\n",
        "#     highest_testing_accuracy = max(test_set_post_pruning_accuracies)\n",
        "#     number_of_nodes_in_best_tree = nodes_counts[np.where(test_set_post_pruning_accuracies == highest_testing_accuracy)[0][-1]]\n",
        "\n",
        "#     # Provide a visualization of the accuracies as a function of the number of nodes\n",
        "#     plt.plot(nodes_counts, training_set_post_pruning_accuracies, label='Training accuracy')\n",
        "#     plt.plot(nodes_counts, test_set_post_pruning_accuracies, label='Test accuracy')\n",
        "#     plt.scatter(number_of_nodes_in_best_tree, highest_testing_accuracy, linewidths=10, color='red', label=f'best test accuracy ({number_of_nodes_in_best_tree} nodes)')\n",
        "\n",
        "#     plt.title('Accuracy vs Number of nodes', fontsize=20)\n",
        "#     plt.xlabel('Number of nodes')\n",
        "#     plt.ylabel('Accuracy (%)')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neLVhkhcixEx"
      },
      "source": [
        "import copy\n",
        "\n",
        "def post_pruning(node, training_data, test_data):\n",
        "    # First, count number of nodes and calculate accuracies on the original (pre-pruned) tree (training AND test)\n",
        "    # to keep track for best node to remove at each iteration \n",
        "    # and to find the best overall tree, its accuracy and its number of nodes\n",
        "    counts = [count_nodes(node)]\n",
        "    training_set_post_pruning_accuracies = [calc_accuracy(node, training_data)] \n",
        "    test_set_post_pruning_accuracies = [calc_accuracy(node, test_data)]\n",
        "    pruned_trees = []\n",
        "\n",
        "    while len(node.children) != 0:\n",
        "        parent_nodes_of_leaves = get_parent_nodes_of_leaves(node)\n",
        "        temp_accuracies = []\n",
        "\n",
        "        # Take the fully grown tree and iterate over all nodes that have at least a single child which is a leaf.\n",
        "        for i in range(len(parent_nodes_of_leaves)):\n",
        "            # For each such node, temporarily replace it with a leaf using the popular class of the training data that reached that node. \n",
        "            current_node = parent_nodes_of_leaves[i]\n",
        "            temp = current_node.children\n",
        "            current_node.children = []\n",
        "            current_node.set_is_leaf(True)\n",
        "            frequent = get_frequent_prediction(current_node.data)\n",
        "            current_node.set_prediction(frequent)\n",
        "\n",
        "            # Calculate the accuracy on the testing data\n",
        "            temp_accuracies.append(calc_accuracy(node, test_data))\n",
        "\n",
        "            # return to original state\n",
        "            current_node.children = temp\n",
        "            current_node.set_is_leaf(False)\n",
        "            current_node.set_prediction(None)\n",
        "        \n",
        "        # After performing it on all possible nodes, pick the node with the best testing accuracy \n",
        "        # and permanently change it in the tree.\n",
        "        max_index = np.argmax(temp_accuracies)\n",
        "        new_leaf = parent_nodes_of_leaves[max_index]\n",
        "        new_leaf.children = []\n",
        "        new_leaf.set_is_leaf(True)\n",
        "        frequent = get_frequent_prediction(new_leaf.data)\n",
        "        new_leaf.set_prediction(frequent)\n",
        "\n",
        "        counts.append(count_nodes(node))\n",
        "        test_set_post_pruning_accuracies.append(temp_accuracies[max_index])\n",
        "        training_set_post_pruning_accuracies.append(calc_accuracy(node, training_data))\n",
        "        pruned_trees += [copy.deepcopy(node)]\n",
        "\n",
        "    highest_testing_accuracy = np.max(test_set_post_pruning_accuracies)\n",
        "    number_of_nodes_in_best_tree = counts[np.where(test_set_post_pruning_accuracies == highest_testing_accuracy)[0][-1]]\n",
        "\n",
        "    for t in pruned_trees:\n",
        "        if calc_accuracy(t, test_data) == highest_testing_accuracy and count_nodes(t) == number_of_nodes_in_best_tree:\n",
        "            tree_post_pruning = t\n",
        "            break\n",
        "    \n",
        "    # Provide a visualization of the accuracies as a function of the number of nodes\n",
        "    plt.plot(counts, training_set_post_pruning_accuracies, label='Training accuracy')\n",
        "    plt.plot(counts, test_set_post_pruning_accuracies, label='Test accuracy')\n",
        "    plt.scatter(number_of_nodes_in_best_tree, highest_testing_accuracy, linewidths=10, color='red', label=f'best test accuracy ({number_of_nodes_in_best_tree} nodes)')\n",
        "    \n",
        "    plt.title('Accuracy vs Number of nodes', fontsize=20)\n",
        "    plt.xlabel('Number of nodes')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return tree_post_pruning, highest_testing_accuracy"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQlAobkvpAo-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiUTUM6eCI9u"
      },
      "source": [
        "## Chi square pre-pruning\n",
        "\n",
        "Consider the following p-value cut-off values: [1 (no pruning), 0.5, 0.25, 0.1, 0.05, 0.0001 (max pruning)]. For each value, construct a tree and prune it according to the cut-off value. Next, calculate the training and testing accuracy. On a single plot, draw the training and testing accuracy as a function of the tuple (p-value, tree depth). Mark the best result on the graph with red circle. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8i_S8VI1uaS"
      },
      "source": [
        "# chi_table was moved to top of notebook (\"Building a Decision Tree\" part)."
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXpY1zJUqHpR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkvmPIyOCI9u"
      },
      "source": [
        "Build the best 2 trees:\n",
        "1.   tree_post_pruning - the best tree according to post pruning\n",
        "2.   tree_chi - the best tree according to chi square pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0oXahCJo07td",
        "outputId": "0f4d2198-3185-488c-d829-75e7012f9b2a"
      },
      "source": [
        "tree_post_pruning, highest_testing_accuracy = post_pruning(best_test_tree, X_train, X_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEbCAYAAADXk4MCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhV1dXwfytzQgKZGAIBAopMAgEiDrSKIhXF2YpStaJVq9b569fa1ir1fdvXVvs5vyq2imPBodahFisKatVWQHHCCSFAkCEmJCSEzOv7Y597ubm5N9yEXJJw1+95znPu2Xufc9YZ7l5nr7322qKqGIZhGLFLXFcLYBiGYXQtpggMwzBiHFMEhmEYMY4pAsMwjBjHFIFhGEaMY4rAMAwjxjFFYBg9CBEpEBEVkQVdLUtnIiJzROQDEanyru+OrpapLURkmifnvK6WpTMwReAhIr/yHqyKyMiulseIHiIyN+BZ/yFMGd8f/fF9LV+sISKHA08AGcB9wG+AxV0qVIyR0NUCdAdERICLAAUEuBj4aZcKZewrrhKRe1V1fVcLEsPMwv3vfqiq73S1MLGItQgc3wMKgEeALcD5IpLUpRIZ+4I1QDLwu64WJMYZ6K2/6VIpYhhTBI6LvfWDuCZqLnBauMIiki8id4nIVyKyS0TKReQ9Efl1R8t6ZohlYc63wMsvCEjz24pF5CARWSQi20SkWUSmeWUmi8idIvKhd95aT44/ikhWG9d3loi8FrBPsYj8RUSKvPwfe+e+Kcz+A0SkQUQ+DncOr9xh3nGea6PMZyJSJyLZ3raIyPki8o6IlHrybRSRV0TkrLbOF4KngA+AOb5r2xOhnkVAXki7sYgs89ITReRGEfnak/sLEbk4oNylIvKx956UiMhvRCTsf1RERonI37zntFNE/iUi32uj/BwRWSoiFd75PxORG0QkOURZ9eQeICJ/EpFNItIkInMjuEdx3rUsF5FqT7blInJZ4PX4THTABV7SugCTXcEezjHPKzdNRL7v/adqvHuxUEQGhdlvhIg86l1PvYh8422PCFO+v4j8WUS2es9llYicvwfZskXkf7z7u0tEKr3/U6tnIyJJInKViLwvItu9aygWkedF5Ni2ztOpqGpML0B/oB74wts+GGciei1M+SKgzCvzBvB74G7gNaBpL8oqsCzMORd4+QUBaQVe2lvAduA/wO3A/cAkr8z9wFZchfdHL/9Nb7/VQEbQeSTgXKXAn4D/AR4DSoB5Xrl0oBLYAMSHkPeX3jGuiOD+fw7UATkh8qZ4x3kmIO13Xtpa4F5v+2Hgk8ByezjnXO8Y/w0cE+reA9O89Mf39CxC7DMvKH2Zl/6sdx/ne7Jv9dLnAv/Pe1ceAe7wrk+Bnwcdy/fc3/Ce+5veM1oA7AKagLNCyPaQt99G4M/e+/C2l7YUSAjxPn4EFHv39m7gTuD4CO7vE97+G7xrud07jgJPBJQrBOYBq7y8O7zteUDmHs4xz9vnKaDWW9/K7vf7MyA5aJ9DcO9tM/A37935q7ddCRwSVD4X+Jrd/7PA+/x8mGc9FFjn5b3pXft8XGunGbg4qPyTXtmPvft7C/Co9/xv2xd1oKqaIgCu9x7ELwLSVngP7cCgskkBD/kHIY6V35Gy3nZHFYECvwuz31BCV9Q/InQlc4mX/h7QJygvHsgL2L7HK3tiUDnxXuKdwccII+MvCKM0cJWlAicFpJXhKtO0EOVzI3zmc73j/re3/ZK3fXJAmWl0viJYTkAFBwzHfYRs996VQQF5mcC3OIWcEJAe+NxvDTpPEdDgHa93iOv9K5AatM88L+/qEO+j4iqlhOBrbePezvH2ex9ID0jvhftftfo/tHVP2ziPT+4dwLigPF/lOjvovfzMSz8nqPxZXvrnQFxA+nwv/fYw9zncs24Gzg5Kz8QpvF1Afy+tj1d2BaH/p60+jqK17JOTdNfFeznW4L6iAv+EV3gP+fdB5c/w0p+P4NgRl/XKd1QRbCHoyyfC664EXg9K/9g75sQIjjHWK/tiUPpxXvpDEcqS793/5UHpSbhKfystK8IyXKXZrmsOOvZcWiqCMUCjV1EkeGnT6HxFMD3EPq97eReGyHvYyxsa4rlXENSiC5Lv/IC0D3AVV6uvbJyC/xZ4L8T7WAf0a+e9fdXb93sh8qZ7ecHvXdh72sZ55gU+w6C8o7282wLSpnpp74Q53lte/pHediLuY2YHIT5oAmSeF5A2wUt7Osw5TvHyL/e2e3vbbwPS0fe5M5ZY9xo6BjgAeEVVNwWkP4lrOs8VkRtUtcFLP8xb/yOCY7en7N7woarWhcoQkUTgx8DZuMquDy37hQYFlO2FM4ttVdUP9nRSVf1URN4EjheRwaq60cu6xFvfH4nwqloiIq8BM0RkjKqu9rJOArJxX2ONAbs8AVwJrBaRp3AmkndVtTKS84WRYbWI/NmT/RLgfzt6rD2wIkSar4N0ZYg83zuZDwR7Nb2vqlUh9lkGnA9MBB4RkTRcBfUtcI2IhJKrDhgdIr1YVbeF2qENJuG+cpeFyHsDp/QntvOYbRHqnvrexcB+sEne+vUwx3kd+A5OtjeBUUAa8FaYd2sZ7j4Hcri37hPcT+TR11uPBlDVHSLyIu5dXyUiz+IU0n9UtSaMnFEh1hWBr9JaEJioquXeAzoDp8Wf8bIyvXWg0ghHe8ruDVvayFuE6/Rei7NpbsH96QGuwXnM+OiIvP8LHIlzvb1JRAYAJwOrVPW9dhxnATAD98f6uZfm+5M9ElT2Wtz1XIAz610PNIrIy8D/UdU17ThvIDcCP8Bdx2MdPEabhKlQfEqurbzEEHlbw5zG9z708dZZuBZgX+CmCMQMdaz20AcoV9X64AxVbRSRb4F+HThuOCpCpPnuW3yQXACbwxzHl+77H/jK7+k+B5LjrWd4SzjSA36fhXvnf4AbPwFQKyLPAD9V1XDn71Ri1mtIRPoCp3qbfwnwVlDPk+EML++SgN18L11Ij4Qg2lMWXBMxnGLODJPu268VnhfMacASYKSqXqCqv1DVecDNONPL3sgLzua8FfiRiMQDF+Ku4YF2HAPgOVwT/FwRiReRfsDxuNbOh4EFVbVJVe9Q1Qm4jv4zvP1PBhaH8oCJBO8Pdyuukrq+jaLN3jrUs2rrOXU2/cOkD/DWlUHrD1RV2lpCHCvku7UHKoFsrzXaAhFJwHXA7ujAcfcW330YECY/L6icb72n+xzqHFfv4V77vKRQ1V2qOk9VDwKGAOcC//LWz7Q+RXSIWUWA++JMwjXJ/xxmKQWOFZFh3j7/9tbHR3D89pQF18E3ODjRq2ALIzxGIAd66xeCTCvgvHFSAxNUdSfOO6S/iETUdPdMZn/CKY+TcC2Dapz5JmJUdRfO62MgcCzu6yiB1q2B4P22qepfVXU2rml/AM681VFuw5lqrsWZY0Kx3Vu3ela4TsR9xSQRyQiRPs1bfwCgqtXAp8BY8Vxwo8wHuHrlyBB5R+K+0t/fB3IE4zN3TguTf7S39sn2OVADFIpInxDlQx3H95//bgfkQ1U3quoTuH62NcB3RCRnD7t1Dl3ZQdGVC/AF7otnShtl/ssr81tvO9ATaE6I8uG8htos623/gxCdbLjmvM+DoyAgvcBLWxBG9sO8/GeD0vvhlJ/ibMCBeRcT3msojgCvoYD0IbimeIm37wMdfB6+zrwncH/GBoI6KnGmrKkh9k3E/dEVGB3BueYSvqPxQi/vK0J3Fvs8TJ4MSh8HVNFGZ3EYWRYEP9uAvHle3rQQz10J7zVUQUuvId81/Y3QHcZZeC7HAWlKGOeFPdzbHwS8Q2kB6WlemtLaayfsPWjjPK3uTVv/DZx57HMv/ftB5b/vpX/B3nsNvYnrB2nV+R/wnvTzfvclyOPJS8/AmaoaCOEQEI0l6ifojgu7vTs+2kO5Apwp4Bt2e5MUAeW+PwrO7/cO4BWgMcQLE2nZ6d65dnl/jP+H+8LYivPzbq8iiMc1MRV4B/gD7gt7G65DahOtFYHg3AXVK/cgztd6Ac4nfF6Yc/l8qpWgCqWdz+UrnDul4loywfmZ7K6kF+LGZdyJGxOhRO6hNZfwiiAO5z/vu55gRZACfOnlvYkzJy3C+bIvClM5LKPzFUF7xxH4XHHLcM4Qt+Aquldx/Ub3B5XvkCLw9vXdh3U4P/r/x+5xEQvbcw/aOEere7On/wZwKM4s1YQza/4ON7ajyUs/NKh8R8YR5Ae8H6twZtLf4z5wfF55h3llC73tj4DHvePfi3MMUODOjv6X2v3M9tWJutPC7gEvV0VQ9p9e2dMC0obgOkrX4SquMtyArl+G2L89ZU/GeUHUeuUW4sYCtPqjhHvZg46X7Z272Dvm197Ln+alFYfZ7xxcRVPp7bfOu2chK3l2u8UtDydLhM/lBnZXwGeEyE8EfoZrPW3wZCvFKcxLgaQIzzOXMIrAyz+OMIrAyx+Mq+zKvUphOXA6e3AfDXOuVs82IG8e4RXBApz3yfM4hVCDc0M8ro3rPhE3ZmKb9y5uwX2l/zcwKqjs3iiCOOBy712u8ZaVwE8I+OKO5B60cY5W9yaS/wYwEjdA0vfFvRlXCY8Mc54BuMF4pd6zXuW9PyGftbdPBm5Q5UqcqXQX7j/0d1yfYy+vXCbOSeF13IdZnSfPMtx4jH3mUiqeQIbRYTxXuZuAi1T1z10sjmEY7cQUgbFXeB2WX+G+1gfrPvZ/Ngxj74n1cQRGBxGRWbhBOifhXOx+akrAMHompgiMjnImzgV3K66T6/auFccwjI5ipiHDMIwYp8e1CHJzc7WgoKCrxTAMw+hRrFy58ltV7Rsqr8cpgoKCAlasCBVnyjAMwwiHiISdjjWWQ0wYhmEYmCIwDMOIeUwRGIZhxDhRUwQi8pC4ydQ/CZMv4iZ1XyMiH4nIpFDlDMMwjOgSzRbBAmBmG/nHAyO85RLgvijKYhiGYYQhaopAVd/EBeUKxynAo+r4N5ApInltlDcMwzCiQFf2EQxi99yi4OLZh5wdS0QuEZEVIrKitLR0nwhnGIYRK/SIcQSqOh8XO52ioiIbCm0Yxn6PqvJtdT0byneyobyGDWW7OGZUP8blh5owbe/oSkWwiZbT/eUT/YneDcMwug11jU2UbN/FhrIaV9mX17C+rIaN3u9dDU3+siKQnZ603ymCF4ArRGQhbuagSlXd3IXyGIZhdCqqSvnOen8lH1jhbyivYcuOWgLDvaUmxjMkO40hOWl8Z0Su//eQ7DQGZaaSkhgfFTmjpghE5C+4WXxyRaQEN3FJIoCq3g+8DJyAm6S5BrggWrIYhmFEi/rGZjZV7Aqo7D1TTvkuNpbXUF3X2KJ8/97JDMlO44gDfBV9qltn9yI3PQkR2efXEDVFoKpz9pCvuKnrDMMwui2qSuWuBtYHfs0H/N5cuYvmgK/65IQ4r2JP49Bh2Qz1vuiHZKcxODstal/1e0OP6Cw2DMOIJg1NzWyuqGW9r2M2qLKvqm35VZ+bnszQnDSmDMtmcHYaQwNMOH3Tk4mL2/df9XuDKQLDMGKCyl0NbPQ6Y3fb6V3F/01FLU0Bn/VJ8XHkZ6cyNDuNoqFZrrLP6eV91aeSlrR/VZ3719UYhhHT7Kht4PPNVXxdWu2v7H2Vf+WuhhZlc3olMTg7jUlDsji10JlthmSnMTQnjf4ZKT3uq35vMEVgGEaPQ1XZWL6L1Zt38Jlv2bKDjeW7/GUS44X8LFfBj8/vw9DsXv7KfkhOGunJVv35sDthGEa3Zld9E19srdpd4W/ewWebq/zeOCIwLLcX4/MzOfuQIYzJ682I/unk9UklPoa+6vcGUwSGYXQLVJWtO+r4bPOOFl/6677d6ffKSU9OYNSADE6fNIjReb0Zndebkf0zSE3qfp44PQlTBIZh7HPqG5tZs626hVnns81VlO+s95fJz0pldF5vThw/kNF5vRmT15v8rNSYst3vK0wRGIYRVcp31vsr/NWeWWfNtioamtxnfnJCHCMHZDBjdH/GDHRf+aPyMuidktjFkscOpggMw+gUmpqV4rKdrP6mpS1/y45af5l+GcmMzuvNUQf1ZczA3ozJy6AgpxcJ8TZZYldiisAwjHZTVdvA51uqAr70q/hiyw5qG5oBSIgTDuyXzuEH5DA6L4MxeX0YnZdBTnpyF0tuhMIUgWEYYVFVSrbvCurArWJDeY2/TGZaIqMH9OYHU4a6Sn9gbw7sl05ygnXg9hRMERiGAUBtQxNfbq0KMO1U8dmWHf7wCiIwLKcX4wb1YXZRvuvAHdibAb1TuiRQmtF5mCIwjBhDVSmtqmN1QOftZ5t3sLa02u+m2SspnlF5vTmlcKDfTXPUgIz9LrSC4bCnahj7MQ1NzXxd6tw03Ze+q/TLAtw0B2U6N80TDh7g/8ofnJVmbpoxhCkCw9hPqKip93/h+8w7a7ZVU9/kOnCTEuIY2T+D6aP7+b/yRw/oTZ80c9OMdUwRGEYPo6lZWV+201X4myv9X/mbK3e7afb13DS/e1AuY7xKf3iuuWkaoTFFYBjdmOq6Rr7Y4twzfeadL7ZU+eeyjY8TDuybzqHDsnd/5ef1pm+GuWkakWOKwDC6AbUNTWwsr2Hdtzv9/vmrN+9gfdluN83eKQmMGdibs6cM9odcOLBferec8croWZgiMIx9RHVdI+vLdrK+rIbisp1sCFhvDpjEXAQKcnoxdmBvvj/JuWmOHtibgX3MTdOIDqYIDKOTaGhqZktlLZsra9lUUcOGsl2u4i+vYX3ZTr6trm9RPjc9iaE5vThseA5Dc3pRkOti5R/UP4NeFivf2IfY22YYEbCrvontNfWU76znm4pdbqmsZVPFLjZX7OKbilq2Vu3+qvcxsE8KQ3LSOHZ0f4bm9GJoTpq39LKJUYxug72JRsyjqlTUNLCubCfry3ZS/K37gl9XVsO2HbVsr6n3x9AJJCkhjoF9UhiYmcp3RuQyMDOVQZkp5PVJZWBmCvlZaWa/N3oEpgiMmEBVKd9ZT3FQRe8q/p3s8MIogLPRD+yTyrDcXow4MJestEQy05LISksiu1cSAzNd5Z/TK8ls9sZ+gSkCY7+gtqGJ0qo6Sqvr+Laqjm+rnQnH95W//tsaqup2V/ZxAvlZzkxzSuEghuakMSy3F0NzejE4O9UCphkxhSkCo8dQ39jM+rKdrNlWzVfbqvl8i/Op37ajrkUl7yM+ThiclcrQnF5MHpJFQW4vCjw7fX5WGkkJNrjKMMAUgdHNaGpWtu6opWS787j5utRV/GtLq1lfXkNT8+7e2KE5aYzsn8F3R/Slb0YyfdOT6ZuRTK63zklPItFG0hrGHjFFYOxTfC6WJdt3UbK9hk0Vu1r83lxRS2NAZZ8YLwzL7cXIARmcMC6PA/ulc0DfdIb37WUulobRSdg/yehU6hqb2FxR61XwNWza7qvod7mKvnIXAfU8ItA/I4VBWalMGpJF/oRUBmWmkZ+VyuDsNAZnpVp8HMOIMqYIjHbR2NTM5spaNm6voaR8l1tv38XGcrcO9qWPE8jrk8qgzFQOHZZNflYqg7JSyc9ylX1en1Sz1RtGF2OKwGhBc7NSWl3HxvKaFpX9Rm+9ubK2hZ3eV9HnZ6Uy9cBcBme7St9X0Q/ok2J2esPo5pgiiDFUle01DZQEVO6u0nemnJLtu6hvbDl4qm9GMoOzUpk8NIvBWYFmmzTyMq2iN4yeTlQVgYjMBO4E4oE/qeotQflDgYeAvkA5cK6qlkRTpliguq7RVe4BFfzGct+6hp31TS3KZ6YlMjgrjVEDMjh2dH8GZ6WS71X0+VmpNjrWMPZzoqYIRCQeuBeYAZQAy0XkBVVdHVDsNuBRVX1ERI4B/gc4L1oytaCpCVatgn//G8rLITsbDjsMCgshvntXfLUNTc4u733Bl3hmHN8XfkVNQ4vyvZLiGZztKvXDhuf4O2F9aRkpNkOVYcQy0WwRTAHWqOpaABFZCJwCBCqCMcB13u+lwN+iKI9DFRYsgJtvhuLi1vkFBXDjjTB3rnNp6QIamprZXFHrvuADKnhfp+y2qroW5ZMS4sjPdF/x4/P7+M02PhNOVlqihUIwDCMs0VQEg4CNAdslwKFBZT4ETseZj04DMkQkR1XLAguJyCXAJQBDhgzpuETV1XDmmbB4cfgyxcVw4YXw1FPw9NOQnt7x84WhuVnZVlW32z7vM9t4lf6WHS07ZOPjhLw+KQzOSmPayL6uks9OZXBWGoOz0+ibnmwTjRuG0WG6urP4p8A9IjIXeBPYBDQFF1LV+cB8gKKiIg3OjwjVPSuBQBYvduVffrnDLYP6xmY+3lTB++srWFe20+9iuWn7Lv+E4j76905mcFYaUzwXy8DKPq9PivnSG4YRNaKpCDYBgwO28700P6r6Da5FgIikA2eoakVUpFmwIHIl4GPxYnjkEWcmYncEy/qmZhoalZqGRiprGthe08BXW908slW1jeyobWDbjjo+LKmgxuuYze6VxOCsVMbk9eZ7Y/v7v+bzs5y7pXXIGobRVURTESwHRojIMJwCOBv4QWABEckFylW1GfgFzoOo82lqcn0CYdiVkExlSjp1CYkUZw2kpHc/NvXpR3HWQDa9XUPVt0vZWd/Et9X1LUw2wSTECb2SE8hMSyQtKYFTJw7iyBG5FBVkk5tuk4kbhtE9iZoiUNVGEbkCeAXnPvqQqn4qIjcDK1T1BWAa8D8iojjT0E+iIsyqVVBczJIDpjB/ymnsSkyhKrkX1ckp5KRV0yuuttUujc1xJFY0kF25lYKU4aQOzqVvbxfQLDUxnvh4ISUxjuzUJHolJ3DQgAxSgkMXi0C8eeQYhtG9iWofgaq+DLwclHZjwO9ngGeiKQPgXESB/xw8jnFDN3LEzo8ZkbyJ/ikVJMe3Dl/sJxXIA769A77twHklDo7+FRz5045IbRiGsU/o6s7ifUN5OQBHD/yII5K/gGRgYyNUKmxpgq3NtJpsNlEgXSBF4Nhj4eij23/etcvg9f+CDe/C2NNh7GmQlLbXl2MYhtGZxIYiyM4GIEGaKW3qQ9/fb4SGPewTyNknwJEdsFoddhm8eRt88gw8fzm8fSccfjkMPhTS+0NqVpeNVTAMw/ARG4rgsMPcWqCJuPYpAYDDD+/YeZN6wbE3wfQbYfXzsPS38OLVu/PjEp1CSO/n1hn9A7YH7E7r1Q8SUzomg2EYxh6IDUVQWAgFBQig2s4v8GHDYMKEvTu/CIw9FcacAls+grI1UL0Nqra4dfVWqNwIm1bAzm+BEJ5JKX085eBTGgG/A5e0bGtlGIbRLmJDEcTHu7AR798Tqoptmxtv7LzYQyKQN8Et4WhqhJ2lTjlUb4PqLbt/+xTHppUuraGm9f5xiUEKol+Q0gj4ba0MwzCIFUUAblDY539unyKYORPOPz9KAoUhPgF657mlLVShvhqqtnqKInDxlEZliVMaO0sJ38oIalGEMk+lZkGcjWw2jP2V2FEEIkhuLrpjS2TlZ850sYa6q5lFBJIz3JJ7YNtlmxqh5lunJEIpjqqtEbYy+gWZp/q3ViTWyjCMHkfsKAKAOEETEuHhh91I43XrWpcZNsyZg84/v/sqgfYSn+DMQxkD3LiItqir2t1vEdiH4Vt2tNHKkHjoPxbyD4HBU9w6e/j+cx8NYz8lthSBKirizETnnQcffgjvvrt7PoLDD3cdw918PoKo4mtl5BzQdrnAVobPFLV9HZSsgI8WwYo/u3Kp2Z5iOMStB012xzcMo9sQU4pAaAa8r9P4eJg0yS1G+wlsZQTT3ASln0PJcti43K2/esXLFOg3ZrdiyJ8COQdaH4RhdCExpQhQRTEzRdSJ80xE/cfC5Lkubdd2Z1LyKYZPnoOVC1xeSh9PKQS0GlIzu0p6w4g5YkoRiCmCriM1Cw481i0Azc1Q9pXXanjPmZSW3YK/3yF3pFMI/UZD31HQbxT0GWz9DYYRBWJKEYApgm5DXBz0HemWiee6tNod8M37u01KX78GHz65e5+kdMg9yCmHfmNg+FHQ/2BTDoaxl8SeIrBKo/uS0huGT3OLj5pyKP0CSj9z622fwZolsOoJl9+rLwyc6BTCgIOh/zjX0R0Xwx3+htFOYkoRiAZ0Fhs9g7RsGHq4WwLZsRnWLoW1b7iwHV+/Ds1eSPGEVK/VMNqZkzKHQKa37j3I5ogwjCBiShE405B5p+wX9M6Dwh+4BaCxznkqbfkEtn4CWz52yqFqCy3GO0gcZA2DMxdA3viukNwwuh0xpQgEbX+sIaNnkJAcOo5TYx3s2AQVG6Biowvu9958ePgEKJgKw46CYUe6PgdzYTVilJhSBKhax2KskZDsRjdnD9+ddtBMeP8RWPcmfLnYpaXlwrDvOqUw7CgbEW3EFDGlCASl2UxDxqBJbgHXSlj3pre8AZ8+59L7DHZKYfAU6DfW9Tckp3edzIYRRWJOERhGCzIHw8Rz3KLq5opY94ZTDF/8Y7d3EkDmUDdIrt8Y6D/GeSplH+BGWRtGDya23mBVVKxFYIRBBHJHuOWQi9ygt8oNsHU1bPsUtn7qfn/5CmiT2yc+Gfoe5FoN/cfsXmfkmWnJ6DHElCJoEWvIMPZEXBxkFbhl1Am70xtq4dsvYdtqpxy2rXYtiI8W7i6TkgnZwwLcV4d4vwe7tYXQMLoRMaUILNaQ0SkkpjjX02D305pyN+DNpxwq1rvtr/4JjbUtyyb3dmamoVOh4DuuLyKp1767BsMIIKYUgViICSOapGU7l9SCqS3TVd1c1JUbdruxVmxwQfj+dTu8dRvEJcDASTD0CBdGI3MIZA2FjIHWB2FEnYjeMBHJAgYCu4BiVW2OqlRRw9xHjS5ABNL7umXQ5JZ5dVWw4T9Q/BasfxvevWf3CGlwCqL3IKcUModAZsFuJZE51M0KZ+MfjL0krCIQkT7AT4A5QBJQCqQA/UXk38D/qurSfSJlJyHWWWx0N5IzYMSxbgForHeD3io2ONNSxQbYvt79/upVNxFQIPHJu8NnZA4NUBIF7nevXPv4MfZIWy2CZ4BHge+qakVghohMBs4TkeGq+udoCtiZiLUIjO5OQpILmhduhriGXZ5paT1sL26pML5ZBbvKW5ZPTAuhJAJ+p2Taf8IIrwhUdUYbeSuBlfn7KUIAACAASURBVFGRKKpYrCGjh5OY6txV+x4UOr+uKqAVEdSq2PAu1O1oWT65d3glkTnEphWNESLuhRKRvsDVQCpwv6p+FTWpooTQTLN1Fhv7M8kZu2eHC8Wu7aGVRPlaF821oaZl+dTsEEqiYLdLbGJq1C/JiD7tcUf4I/AgLpTjk8AhUZEoiohizWAjtknNcsvAwtZ5Pu+mig1QUdyyf2Lrp26kdVN9y3169Qvdksgc6sZLJCTtk8sy9o62OotfAX6rqm96SUlAMU4RJEdftGhg7qOGEZZA76b8ya3zm5tdZ3WLTuxi97tkuYvT5Btx7Q4IvQeGVhL+uSHMNbY70NZTmA3cICKXATcAvwb+B2caunwfyNbp2Mhiw9gL4uLcPBC982DIYa3zmxqh6puWLQnf7+J/wUeLaDk3RDz0GeQUg79VEaA00geYa+w+oq3O4krg/4rIcOC3wDfAFcEeRG0hIjOBO4F44E+qektQ/hDgESDTK3O9qr7c7quIVB5zHzWM6BGfsLvvoOA7rfMb62FHSWslUbEhjGtskjMvBbckfH0UvfqaqbeTaMs0dABwGVAP/B/gAGCRiPwduFe1RRsw1P7xwL3ADKAEWC4iL6jq6oBiNwBPqep9IjIGeBko2IvraROLPmoYXUhCUuu5IQIJdI2tWN+yU3vzh1BT1rK83zU22D12iJuFzuI5RUxbpqG/ANcAvYDHVHU6cJyI/BD4JzB9D8eeAqxR1bUAIrIQOAUIVAQK9PZ+98G1OqKI9REYRrclUtfYVu6x693o7LrKluXTclyY8JwDvPVwyDnQKSJzi21BW4ogGVgHpANpvkRVfVREno7g2IOAjQHbJcChQWXmAf8UkStxCufYUAcSkUuASwCGDBkSwalD4waUmWnIMHokkbjG+pTE9nVQ9rXnFvsGfPiXlmXT++9WDtkHOAWRc4BTEjHoEtuWIrgcuAdnGro0MENVd3XS+ecAC1T1jyJyOPCYiBwcHMtIVecD8wGKioo6bN8Riz5qGPsvPtfY4HmrAep3OqVQ9jWUfw1la936y1dgZ2nLsr0HOYWQ4ykIX6siq8BNfbof0lZn8dvA23tx7E3A4IDtfC8tkB8BM73zvSsiKUAusG0vztsGFmLCMGKSpF4wYJxbgqnd4SmHr1sqi9XPu1aGD4mDPvktlYNvnTkE4hP33fV0Mm11Fr8IPAC8oqoNQXnDgbm4SKQPhTnEcmCEiAzDKYCzgR8EldmA62tYICKjcUHtgtRz5xGHYu6jhmG0IKU3DJzolmBqyoNaEl+76UxLVrQM1xGX4DqsA5WDr1XRZzDExe+76+kAbZmGLgauA+4UkXJ2Rx8tAL4G7lHV58PtrKqNInIF8ArONfQhVf1URG4GVqjqCzhvpAdF5Fpcx/FcVY2ia4+i1iIwDCNS0rLdkl/UMt03CtvfkvAURNlaN2YiMFRHfJLzYgpUDr5+iYy8bjFWoi3T0BbgZ8DPRKQAyMPNR/ClqtaE2y/oGC/jXEID024M+L0amBq8X7QQbbagc4Zh7D2Bo7CDB9epQtWWli0IX6tizWvQVLe7bEKqpxyCO60PgPR++8yUHdH4blUtxoWX6NEIINYiMAwjmojsHoEdPLCuuRl2bGrZgij/GrZ9Dl8shuYAK3xShpv3OrAFMfRw12ndycRYoA/zGjIMowuJi/MmEhoMw6e1zGtqdJMSBfZHlH/t5plY/YKL43Ti7VB0YaeLFVOKwDqLDcPotsQnuBZA9jBaDalqrHcD51Kzo3LqPRrMReQkkf1lFJbFGjIMoweSkAS5I6BXTlQOH0mteBbwlYj8QURGRUWKfUQczTaOwDAMI4g9KgJVPReYiHMZXSAi74rIJSLSQ4N1mCIwDMMIJCI7iaruwE1mvxDnRnoa8L4XI6jHYCEmDMMwWhNJH8HJIvIcsAxIBKao6vHABNyAsB6DmGnIMAyjFZF4DZ0B3B4wZSUAqlojIj+KjljRQcCijxqGYQQRiSKYB2z2bYhIKtBfVYtV9bVoCRYNhGYzDRmGYQQRyefx00BgWOgmL63H4VoEpggMwzACiUQRJKhqvW/D+50UPZGih9iAMsMwjFZEoghKReRk34aInAJ8Gz2RoofNUGYYhtGaSPoILgWeEJF7cJ/TG4EfRlWqKCEWhtowDKMVe1QEqvo1cJiIpHvb1VGXKkoIzYiZhgzDMFoQUdA5EZkFjAVSfGGcVfXmKMoVFQQs1pBhGEYQkQwoux8Xb+hKXF16JjA0ynJFhThtxjqLDcMwWhLJ5/ERqvpDYLuq/gY4HDgoumJFEesjMAzDaEEkiqDWW9eIyECgARdvqMfhvIZMERiGYQQSSR/BiyKSCdwKvI+bZP7BqEoVJdzENNZHYBiGEUibisCbkOY1Va0AnhWRl4AUVa3cJ9J1MuY+ahiG0Zo2P49VtRm4N2C7rqcqAbCRxYZhGKGIxE7ymoicIdLzP6Wtj8AwDKM1kSiCH+OCzNWJyA4RqRKRHVGWKypYiAnDMIzWRDKyuIdOSdkaMw0ZhmG0Zo+KQESODJUePFFNT8BaBIZhGK2JxH30/wb8TgGmACuBY6IiURSJsz4CwzCMVkRiGjopcFtEBgN3RE2iKKGq1llsGIYRgo7YSUqA0Z0tSLRpVogXG1BmGIYRTCR9BHfjRhODq0ULcSOMexSq3iVYi8AwDKMFkfQRrAj43Qj8RVXfjpI8UcMUgWEYRmgiUQTPALWq2gQgIvEikqaqNXvaUURmAncC8cCfVPWWoPzbgaO9zTSgn6pmtucCIqW5ucl31mgc3jAMo8cS0chiIDVgOxVYsqedRCQeF57ieGAMMEdExgSWUdVrVbVQVQuBu4G/Rip4e9ndIrA+AsMwjEAiqRVTAqen9H6nRbDfFGCNqq5V1XpgIXBKG+XnAH+J4LgdQpub3Q8zDRmGYbQgEkWwU0Qm+TZEZDKwK4L9BuEmuvdR4qW1QkSGAsOA18PkXyIiK0RkRWlpaQSnbo2Ln4fNWWwYhhFEJH0E1wBPi8g3OAP7ANzUlZ3J2cAzvn6IYFR1PjAfoKioSEOV2RPNnmnI5iw2DMNoSSQDypaLyChgpJf0hao2RHDsTcDggO18Ly0UZwM/ieCYHUa9zuL9IIiqYRhGpxLJ5PU/AXqp6ieq+gmQLiKXR3Ds5cAIERkmIkm4yv6FEMcfBWQB77ZP9PbR3GwtAsMwjFBEUite7M1QBoCqbgcu3tNOqtoIXAG8AnwGPKWqn4rIzSJyckDRs4GF6nfriRLWWWwYhhGSSPoI4kVEfBW15xaaFMnBVfVl4OWgtBuDtudFJureod7gaOssNgzDaEkkimAxsEhEHvC2f+yl9ShsZLFhGEZoIlEEPwcuAS7ztl8FHoyaRFFid2ex9REYhmEEssdaUVWbVfV+Vf2+qn4fWI0bBdyj8HUWW4vAMAyjJZG0CBCRibiRv7OBdUQxFES08A9RsBaBYRhGC8IqAhE5CFf5zwG+BRYBoqpHh9unO2N9BIZhGKFpq0XwOfAWcKKqrgEQkWv3iVTRwO8+ai0CwzCMQNqqFU8HNgNLReRBEZlOD47h7AsxYe6jhmEYLQmrCFT1b6p6NjAKWIqLOdRPRO4Tke/tKwE7C984AjMNGYZhtCQSr6GdqvqkN4l9PvABzqW0R+FzHzXTkGEYRkvaVSuq6nZVna+q06MlUNQw91HDMIyQxMznsX8+AmsRGIZhtCBmakUbUGYYhhGamFEE+ILOWYvAMAyjBTFTKzb7O4utRWAYhhFIzCgC38hijZ1LNgzDiIjYqRVtqkrDMIyQxIwi8E1/ZorAMAyjJbGjCHxB5+Ji5pINwzAiImZqRf/ENBZryDAMowWxowj8Yahj5pINwzAiImZqRfWHobYWgWEYRiAxowhsQJlhGEZoYqZWVBtQZhiGEZLYUQS+iWlMERiGYbQghhSBL/pofBdLYhiG0b2IIUXghZiwFoFhGEYLYkYR4DMN2YAywzCMFsROrWgDygzDMEISM4pAsc5iwzCMUMSOImi2WEOGYRihSOhqAfYVu72GrEUQ6zQ0NFBSUkJtbW1Xi2IYnU5KSgr5+fkkJiZGvE/MKYIYagQZYSgpKSEjI4OCggL7MDD2K1SVsrIySkpKGDZsWMT7RbVWFJGZIvKFiKwRkevDlJktIqtF5FMReTJqwqhNXm84amtrycnJMSVg7HeICDk5Oe1u7UatRSBu5Na9wAygBFguIi+o6uqAMiOAXwBTVXW7iPSLljy+PoI46yMwMBOhsf/SkXc7mrXiFGCNqq5V1XpgIXBKUJmLgXtVdTuAqm6Lnji+6KOmCAzDMAKJZq04CNgYsF3ipQVyEHCQiLwtIv8WkZmhDiQil4jIChFZUVpa2iFhrLPY6C6UlZVRWFhIYWEhAwYMYNCgQf7t+vr6NvddsWIFV1111R7PccQRR3SWuEYM0NWdxQnACGAakA+8KSLjVLUisJCqzgfmAxQVFWnwQSLB7z5qLQKji8nJyWHVqlUAzJs3j/T0dH7605/68xsbG0lICP3XLCoqoqioaI/neOeddzpH2H1IU1MT8fEWC6wriKYi2AQMDtjO99ICKQH+o6oNwDoR+RKnGJZ3vjjWIjBa85sXP2X1Nzs69ZhjBvbmppPGtmufuXPnkpKSwgcffMDUqVM5++yzufrqq6mtrSU1NZWHH36YkSNHsmzZMm677TZeeukl5s2bx4YNG1i7di0bNmzgmmuu8bcW0tPTqa6uZtmyZcybN4/c3Fw++eQTJk+ezOOPP46I8PLLL3PdddfRq1cvpk6dytq1a3nppZdayFVcXMx5553Hzp07Abjnnnv8rY3f//73PP7448TFxXH88cdzyy23sGbNGi699FJKS0uJj4/n6aefZuPGjX6ZAa644gqKioqYO3cuBQUFnHXWWbz66qv87Gc/o6qqivnz51NfX8+BBx7IY489RlpaGlu3buXSSy9l7dq1ANx3330sXryY7OxsrrnmGgB+9atf0a9fP66++uqOP7wYJZqKYDkwQkSG4RTA2cAPgsr8DZgDPCwiuThT0dpoCKMWa8jo5pSUlPDOO+8QHx/Pjh07eOutt0hISGDJkiX88pe/5Nlnn221z+eff87SpUupqqpi5MiRXHbZZa38xz/44AM+/fRTBg4cyNSpU3n77bcpKirixz/+MW+++SbDhg1jzpw5IWXq168fr776KikpKXz11VfMmTOHFStW8I9//IPnn3+e//znP6SlpVFeXg7AOeecw/XXX89pp51GbW0tzc3NbNy4MeSxfeTk5PD+++8Dzmx28cUXA3DDDTfw5z//mSuvvJKrrrqKo446iueee46mpiaqq6sZOHAgp59+Otdccw3Nzc0sXLiQ9957r9333YiiIlDVRhG5AngFiAceUtVPReRmYIWqvuDlfU9EVgNNwP9V1bKoCNRsLQKjNe39co8mZ555pt80UllZyfnnn89XX32FiNDQ0BByn1mzZpGcnExycjL9+vVj69at5OfntygzZcoUf1phYSHFxcWkp6czfPhwv6/5nDlzmD9/fqvjNzQ0cMUVV7Bq1Sri4+P58ssvAViyZAkXXHABaWlpAGRnZ1NVVcWmTZs47bTTADewKRLOOuss/+9PPvmEG264gYqKCqqrqznuuOMAeP3113n00UcBiI+Pp0+fPvTp04ecnBw++OADtm7dysSJE8nJyYnonEZLotpHoKovAy8Hpd0Y8FuB67wlqvhbBDagzOim9OrVy//717/+NUcffTTPPfccxcXFTJs2LeQ+ycnJ/t/x8fE0NjZ2qEw4br/9dvr378+HH35Ic3NzxJV7IAkJCTT75gyHVj7ugdc9d+5c/va3vzFhwgQWLFjAsmXL2jz2RRddxIIFC9iyZQsXXnhhu2UzHLFTK/pGFptpyOgBVFZWMmiQc7JbsGBBpx9/5MiRrF27luLiYgAWLVoUVo68vDzi4uJ47LHHaGpyUXxnzJjBww8/TE1NDQDl5eVkZGSQn5/P3/72NwDq6uqoqalh6NChrF69mrq6OioqKnjttdfCylVVVUVeXh4NDQ088cQT/vTp06dz3333Aa5TubKyEoDTTjuNxYsXs3z5cn/rwWg/MVMr2lSVRk/iZz/7Gb/4xS+YOHFiu77gIyU1NZX//d//ZebMmUyePJmMjAz69OnTqtzll1/OI488woQJE/j888/9X+8zZ87k5JNPpqioiMLCQm677TYAHnvsMe666y7Gjx/PEUccwZYtWxg8eDCzZ8/m4IMPZvbs2UycODGsXP/1X//FoYceytSpUxk1apQ//c4772Tp0qWMGzeOyZMns3q1G5ealJTE0UcfzezZs83jaC8QXwXZUygqKtIVK1a0e7+V/3ySye9cxtrTXmL4hO9GQTKjp/DZZ58xevTorhajy6muriY9PR1V5Sc/+QkjRozg2muv7Wqx2kVzczOTJk3i6aefZsSIEV0tTrch1DsuIitVNaTvccy0CHbPUGYtAsMAePDBByksLGTs2LFUVlby4x//uKtFaherV6/mwAMPZPr06aYE9pKuHlC2z7DOYsNoybXXXtvjWgCBjBkzxj+uwNg7YqZWVN+AMussNgzDaEHs1Io2jsAwDCMkMaMIbGSxYRhGaGKnVvTPUGYtAsMwjEBiprMYfOMIYkf3Gd2TsrIypk+fDsCWLVuIj4+nb9++ALz33nskJSW1uf+yZctISkqyUNNGpxEzisAXhtpMQ0ZXs6cw1Hti2bJlpKend7kisLDR+w8xowj8YajNNGQE8o/rYcvHnXvMAePg+FvatcvKlSu57rrrqK6uJjc3lwULFpCXl8ddd93F/fffT0JCAmPGjOGWW27h/vvvJz4+nscff5y7776b73539wDJ9957L2T46qamJn7+85+zePFi4uLiuPjii7nyyitZvnw5V199NTt37iQ5OZnXXnuNZ599lhUrVnDPPfcAcOKJJ/LTn/6UadOmkZ6ezo9//GOWLFnCvffey+uvv86LL77Irl27OOKII3jggQcQkZDhqH/zm99w+umnc+qppwIuUuns2bM55ZTgiQuNfU3MKALrLDa6K6rKlVdeyfPPP0/fvn1ZtGgRv/rVr3jooYe45ZZbWLduHcnJyVRUVJCZmcmll14athUxatSokOGr58+fT3FxMatWrSIhIYHy8nLq6+s566yzWLRoEYcccgg7duwgNTW1TVl37tzJoYceyh//+EfA+fLfeKOLI3neeefx0ksvcdJJJ4UMR/2jH/2I22+/nVNPPZXKykreeecdHnnkkc6/oUa7iRlFYO6jRkja+eUeDerq6vjkk0+YMWMG4EwueXl5AIwfP55zzjmHU0891f8l3RbhwlcvWbKESy+91D/zWXZ2Nh9//DF5eXkccsghAPTu3XuPx4+Pj+eMM87wby9dupQ//OEP1NTUUF5eztixY5k2bVrIcNRHHXUUl19+OaWlpTz77LOcccYZYWdiM/YtMfQUfC0Cs2ka3QtVZezYsbz77rut8v7+97/z5ptv8uKLL/Lb3/6Wjz9u24wVafjqtmgrbHRKSoq/X6C2tpbLL7+cFStWMHjwYObNm9cqxHQwP/zhD3n88cdZuHAhDz/8cLtlM6JD7NhJbPJ6o5uSnJxMaWmpXxE0NDTw6aef+mf3Ovroo/n9739PZWUl1dXVZGRkUFVVFfJY4cJXz5gxgwceeMAfybS8vJyRI0eyefNmli93M8NWVVXR2NhIQUEBq1at8p8/3Kxfvko/NzeX6upqnnnmGYCw4ajBzTdwxx13AM6sZHQPYkYRqAWdM7opcXFxPPPMM/z85z9nwoQJFBYW8s4779DU1MS5557LuHHjmDhxIldddRWZmZmcdNJJPPfccxQWFvLWW2+1OFa48NUXXXQRQ4YMYfz48UyYMIEnn3ySpKQkFi1axJVXXsmECROYMWMGtbW1TJ06lWHDhjFmzBiuuuoqJk2aFFLuzMxMLr74Yg4++GCOO+44v4kJQoejBujfvz+jR4/mggsuiMKdNDpKzIShfueZOznikxv59qIV5OZbpMJYxsJQdx01NTWMGzeO999/P+T8B0bnYGGowyCe+yhmGjKMLmHJkiWMHj2aK6+80pRANyN2Oou9lk+cdRYbRpdw7LHHsn79+q4WwwhBzCgCVRtQZnSApiZYtQr+/W8oL4fsbDjsMCgsBBtVa+wnxIwiwAaUGe1BFRYsgJtvBm+C9xYUFMCNN8LcuWZuNHo8MVMr2uT1RsRUV8MJJ8CFF4ZWAuDSL7zQlauu3pfSGUanEzOKQNRmKDMiQBXOPBMWL46s/OLFrnwP874zjEBipla0WENGRCxYELkS8LF4MbQjZk5xcTEHH3xw+84RgmXLlvHOO++0O29PFBcX8+STT+6NaN0aVeWYY45hx44dABQUFDBu3DgKCwspKtrtXXnWWWdRWFhIYWEhBQUFFBYWdrosy5Yt48QTT2z3fvX19Rx55JEtxorsDTFTK/pbBDYfgRGOpibXJ9ARbr7Z7b8P2d8VQWdVcsG8/PLLTJgwoUVspaVLl7Jq1SoCxygtWrSIVatWsWrVKs444wxOP/30qMjTEZKSkpg+fTqLFi3qlOPFTK2ovlhD5jVkhGPVqvB9Anti3Tr48MOIizc2NnLOOecwevRovv/97/tDMKxcuZKjjjqKyZMnc9xxx7F582YA7rrrLsaMGcP48eM5++yzKS4u5v777+f2229vNcI4VF5paSlnnHEGhxxyCIcccghvv/02AG+88Yb/q3fixIlUVVVx/fXX89Zbb1FYWMjtt9/eQu7q6mqmT5/OpEmTGDduHM8//7w/79FHH/WPXD7vvPMA2Lp1K6eddhoTJkxgwoQJvPPOO61aRLfddhvz5s0DYNq0aVxzzTUUFRVx55138uKLL3LooYcyceJEjj32WLZu3eqX44ILLmDcuHGMHz+eZ599loceeohrrrnGf9wHH3yQa6+9ttW9f+KJJ9oV+lpVeeqpp5gzZ06rvGXLljFt2jS+//3vM2rUKM455xy/9eG1115j4sSJjBs3jgsvvJC6ujoAFi9ezKhRo5g0aRJ//etf/cfauXMnF154IVOmTGHixIn+e/vpp58yZcoUCgsLGT9+PF999RUAp556Kk888UTE17HHi+xJy+TJk7Uj/Ouxm1Vv6q07K0o7tL+x/7B69erQGffco+qs/R1b7rknovOvW7dOAf3Xv/6lqqoXXHCB3nrrrVpfX6+HH364btu2TVVVFy5cqBdccIGqqubl5Wltba2qqm7fvl1VVW+66Sa99dZbQ54jOG/OnDn61ltvqarq+vXrddSoUaqqeuKJJ/rlqKqq0oaGBl26dKnOmjUr5HEbGhq0srJSVVVLS0v1gAMO0ObmZv3kk090xIgRWlrq/l9lZWWqqjp79my9/fbbVVW1sbFRKyoqdN26dTp27Fj/MW+99Va96aabVFX1qKOO0ssuu8yfV15ers3Nzaqq+uCDD+p1112nqqo/+9nP9Oqrr25RrqqqSocPH6719fWqqnr44YfrRx991OoahgwZojt27PBvFxQU6MSJE3XSpEn6wAMPtCr/xhtvaLh6Z+nSpdq7d2/duHGjNjU16WGHHaZvvfWW7tq1S/Pz8/WLL75QVdXzzjtPb7/9dn/6l19+qc3NzXrmmWf67/UvfvELfeyxx1TVPeMRI0ZodXW1XnHFFfr444+rqmpdXZ3W1NT472dubm5IuUK948AKDVOvxoz76BHDs2ANpCaZ77cRhvLyfbb/4MGDmTp1KgDnnnsud911FzNnzuy0cNTBLFmyhNWrV/u3d+zYQXV1NVOnTuW6667jnHPO4fTTTyc/P7/N46gqv/zlL3nzzTeJi4tj06ZNbN26lddff50zzzyT3NxcwIW5Bnj99dd59NFHARfCuk+fPmzfvr3Nc5x11ln+3yUlJZx11lls3ryZ+vp6hg0b5r+ehQsX+stlZWUBcMwxx/DSSy8xevRoGhoaGDduXKvjl5eXk5GR4d/+17/+xaBBg9i2bRszZsxg1KhRHHnkkf78v/zlLyFbAz6mTJniv2+FhYUUFxeTkZHBsGHDOOiggwA4//zzuffee5k2bRrDhg1jxAgX5ubcc89l/vz5APzzn//khRde4LbbbgNcUL8NGzZw+OGH89vf/paSkhJOP/10/77x8fEkJSVRVVXV4no6QswoAp9BSMQUgREGr/LaF/sHuzGLSKeGow6mubmZf//73/65AXxcf/31zJo1i5dffpmpU6fyyiuvtHmcJ554gtLSUlauXEliYiIFBQV7DD0dTFthrgF69erl/33llVdy3XXXcfLJJ7Ns2TK/CSkcF110Eb/73e8YNWpU2MB2vvPHeY4jvmit/fr147TTTuO9997zK4LGxkb++te/snLlyrDnTE5O9v+Oj4/vcN+GqvLss88ycuTIFumjR4/m0EMP5e9//zsnnHACDzzwAMcccwzgIrsGP9OOEDN9BL4w1Db4xwjLYYft3f6HHx5x0Q0bNvgr/CeffJLvfOc7jBw5stPCUQfnfe973+Puu+/2b/vmTP76668ZN24cP//5zznkkEP4/PPP9xjmul+/fiQmJrJ06VJ/yIhjjjmGp59+mrKyMsB9dQNMnz6d++67D3AtnMrKSvr378+2bdsoKyujrq6Ol156Kex9CgyrHTib2YwZM7j33nv9275WxqGHHsrGjRt58sknw37Fjxw5krVr1wLOLu+71p07d/LPf/6zRf/FkiVLGDVq1B5bSqHOUVxczJo1awAXjfWoo45i1KhRFBcX8/XXXwOuteHjuOOO4+677/b3MXzwwQcArF27luHDh3PVVVdxyimn8NFHHwFQVlZGbm4uiYmJ7ZItFFFVBCIyU0S+EJE1InJ9iPy5IlIqIqu85aLoSeP5eZvXkBGOwkI3YrgjDBsGEyZEXHzkyJHce++9jB49mu3bt3PZjhRrfAAAC2xJREFUZZeRlJTUaeGog/PuuusuVqxYwfjx4xkzZgz3338/AHfccQcHH3ww48ePJzExkeOPP57x48cTHx/PhAkTWnUWn3POOaxYsYJx48bx6KOPMmrUKADGjh3Lr371K4466igmTJjAddddB8Cdd97J0qVLGTduHJMnT2b16tUkJiZy4403MmXKFL8pJhzz5s3jzDPPZPLkyX6zE8ANN9zA9u3bOfjgg5kwYQJLly71582ePZupU6f6zUXBzJo1i2XLlgGuM/s73/kOEyZMYMqUKcyaNYuZM2f6yy5cuLBNs1A4UlJSePjhhznzzDMZN24ccXFxXHrppaSkpDB//nxmzZrFpEmT6Nevn3+fX//61zQ0NDB+/HjGjh3Lr3/9awCeeuopDj74YAoLC/nkk0/44Q9/CDhPp1mzZrVbtpCE6zzY2wWIB74GhgNJwIfAmKAyc4F72nPcjnYW62cvqS46T7WhtmP7G/sNYTuLVVUfeqhjHcUPP7zP5DfaZtasWbpkyZKw+d98840ee+yx+1Ci6HDaaaf5O6ODaW9ncTQ/j6cAa1R1rarWAwuByH22OptRs2D2o5CQvOeyRuwydy4EfBFGxMyZcP75URHHiJyKigoOOuggUlNTmT59ethyeXl5XHzxxf4BZT2R+vp6Tj31VH9n9N4STUUwCNgYsF3ipQVzhoh8JCLPiMjgUAcSkUtEZIWIrCgtLY2GrIbhEIGnn45cGcyc6cpb31OXk5mZyZdffsnTTz+9x7KzZ89uMaCsp5GUlOQ3EXUGXW0wfxEoUNXxwKtAyHH6qjpfVYtUtahv3777VEBj/0S1jdhA6enw8svw8MPO9h+KYcNc/ssvu/KG0U1o890OQzTdRzcBgV/4+V6aH1UtC9j8E/CHKMpjGIDryCsrKyMnJyd8NFoRZyY67zw3Yvjdd3fPR3D44a5j2OYjMLoZqkpZWVm7XUqjqQiWAyNEZBhOAZwN/CCwgIjkqepmb/Nk4LMoymMYAOTn51NSUkLEZsbUVPD8tv18+WXnC2YYnUBKSkq73V2jpghUtVFErgBewXkQPaSqn4rIzbje6xeAq0TkZKARKMd5ERlGVElMTPSPUDUMA6Qj9qSupKioSAMjBBqGYRh7RkRWqmpRqLyu7iw2DMMwuhhTBIZhGDFOjzMNiUgpsL6Du+cC33aiOPuSniw79Gz5TfauwWTvXIaqakj/+x6nCPYGEVkRzkbW3enJskPPlt9k7xpM9n2HmYYMwzBiHFMEhmEYMU6sKYL5XS3AXtCTZYeeLb/J3jWY7PuImOojMAzDMFoTay0CwzAMIwhTBIZhGDFOzCiCPU2b2R0QkWIR+dibtnOFl5YtIq+KyFfeOstLFxG5y7uej0Rk0j6W9SER2SYinwSktVtWETnfK/+ViOyT2V3CyD5PRDYFTJt6QkDeLzzZvxCR4wLS9/k7JSKDRWSpiKwWkU9F5Govvdvf+zZk7/b3XkRSROQ9EfnQk/03XvowEfmPJ8ciEUny0pO97TVefsGerqlLCTd12f60EMG0md1hAYqB3KC0PwDXe7+vB37v/T4B+AcgwGHAf/axrEcCk4BPOiorkA2s9dZZ3u+sLpJ9HvDTEGXHeO9LMjDMe4/iu+qdAvKASd7vDOBLT8Zuf+/bkL3b33vv/qV7vxOB/3j38yngbC/9fuAy7/flwP3e77OBRW1dU7Tfmz0tsdIi6F7TZraPU9g9Yc8jwKkB6Y+q499Apojk7SuhVPVNXMTYQNor63HAq6parqrbcZMTtXOeyE6TPRynAAtVtU5V1wFrcO9Tl7xTqrpZVd/3flfhQrcPogfc+zZkD0e3uffe/av2NhO9RYFjgGe89OD77nsezwDTRUTauKYuJVYUQaTTZnY1CvxTRFaK/P/2zjXUiiqK47+/JhoW9jCsPpRd04zKtFSKpJTqkr0zLUU0THxEWQZFkiBRXxIxKpAM0+whQfZA6YFRPuhDeDW9vp9ZRFHeKBSKlNTVh73OdTzch/dknnOc9YPDzKzZs89/9pkza2btmbU10W3d7OiYDb8C3Xy+EveprVorbR8e8/DJgkJohQrW7uGGfqSr06pq+yLtUAVtL6m9pHqggeQ4vwP2mdmhJnQ0avT1+4Fzy6W9NfLiCKqFQWZ2DTAUeFTSjdmVlu4tq+J532rS6rwG9AD6Ar8As8srp2UknQF8CEw1s2NGYa/0tm9Ce1W0vZkdNrO+pNEWBwK9yyzphJEXR9DqsJmVgJn97NMG4GPSwba3EPLxaYMXr8R9aqvWitkHM9vrf/QjwDyO3q5XnHZJHUgn0kVm9pGbq6Ltm9JeTW0PYGb7gBXA9aRQW2GAr6yORo2+vgvwOxV0zGfJiyNoHDbTe/VHAkvLrOkYJHWWdGZhHqgFNpN0Fp7oeAhY4vNLgbH+VMh1wP5MaKBctFXrMqBW0tkeDqh120mnqH/lPlLbQ9I+0p8CuQToCdRRpmPK48zzgW1m9lJmVcW3fXPaq6HtJZ0n6SyfPx24ldTHsQIY7sWK273wewwHlvudWnP7VF7K3Vt9sj6kpyd2kuJ608utpwl9NaSnCTYAWwoaSXHFr4BdwJfAOW4XMMf3ZxPQ/yTrfY90G/8PKc45vhStwMOkDrPdwLgyan/HtW0k/VkvyJSf7tp3AEPLeUwBg0hhn41AvX9ur4a2b0F7xbc90AdY7xo3AzPcXkM6ke8GFgMd3d7Jl3f7+prW9qmcn0gxEQRBkHPyEhoKgiAImiEcQRAEQc4JRxAEQZBzwhEEQRDknHAEQRAEOSccQVDxSDJJszPLT0l67gTVvVDS8NZL/ufvGSFpm6QVJ7jewZI+OZF1BvkjHEFQDRwEhknqWm4hWTJvlB4P44EJZjbk/9ITBKUSjiCoBg6RxoB9snhF8RW9pD99OljSKklLJO2R9KKk0Z5TfpOkHplqbpG0VtJOSXf69u0lzZK0xpOhTcrU+7WkpcDWJvSM8vo3S5rpthmkl6nmS5pVVH6wpJWSPpC0XdIifwMXSTdLWu/1LZDU0e23edl1wLBMXZ29XJ1vd4/br3Bbve9LzxJ+g+AUJhxBUC3MAUZL6tKGba4GJgOXA2OAXmY2EHgDmJIp152U3+YOYK6kTqQr+P1mNgAYAEzwlACQxjJ4wsx6Zb9M0oXATFJq4r7AAEn3mtnzwFpgtJk93YTOfsBUUq76GuAG17AQeNDMrgJOAx5x+zzgLuBa4PxMPdNJqQwGAkOAWZ6uZDLwiqWEaf1Jb1MHQSPhCIKqwFKWyreBx9uw2RpLOfAPkl7p/8Ltm0gn/wLvm9kRM9tFGqClNyn3zliltMOrSSkcClfSdZZyyRczAFhpZr9ZSj28iDQITmvUmdlPlpKu1bu2y4DvzWynl3nL6+rt9l2W0gK8m6mnFpjmmleS0hxcBHwDPCvpGeBiM/v7ODQFOaItMc4gKDcvA+uANzO2Q/gFjaR2pBGrChzMzB/JLB/h2GO/OM+KkXL0TDGzYxKxSRoM/FWa/GbJ6jxM6f9LAfeb2Y4i+zZJq0l3PJ9JmmRmy0v8juAUJO4IgqrBzP4gDQ04PmP+gRQiAbibNHJUWxkhqZ33G9SQkoEtI4ViOgBI6uVhlpaoA26S1FVSe2AUsKoEPbiG7pIu9eUxXtd2txf6OEZltlkGTMn0MfTzaQ2wx8xeJWXH7FOipuAUJRxBUG3MBrJPD80jnXw3kPLDl3K1/iPpJP45MNnMDpD6EbYC65QGuX+dVq7ULaV3nkZKTbwB+NbMlrS0TQt1HQDGAYslbSLdxcx1+0TgU+8sbshs9gLJEW6UtMWXAR4ANnvI6EpSiC0IGonso0EQBDkn7giCIAhyTjiCIAiCnBOOIAiCIOeEIwiCIMg54QiCIAhyTjiCIAiCnBOOIAiCIOf8C5mx6/a7+6bcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--VSTuIgULTA",
        "outputId": "dbaafa92-bf18-46e7-ac94-43c9a56aeaf5"
      },
      "source": [
        "print(f'tree_post_pruning accuracy = {calc_accuracy(tree_post_pruning, X_test) * 100}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tree_post_pruning accuracy = 88.72476612506155%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h77LduE1i9ec",
        "outputId": "8c2cfcef-6522-498a-e1a6-37b97de6e131"
      },
      "source": [
        "count_nodes(tree_post_pruning)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtkTnBXBESbB"
      },
      "source": [
        "def calcualte_max_tree_depth(node):\n",
        "    if len(node.children) == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        depths = [0]\n",
        "        \n",
        "        for child in node.children:\n",
        "            depths.append(calcualte_max_tree_depth(child))\n",
        "\n",
        "    return max(depths) + 1"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgJZBbszCI9u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "5370e08b-3f1a-4ad9-a322-e25425f0ad56"
      },
      "source": [
        "tuples = []\n",
        "trees = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "p_values = [1, 0.5, 0.25, 0.1, 0.05, 0.0001]\n",
        "\n",
        "for p in p_values:\n",
        "    tree = build_tree(data=X_train, impurity=calc_entropy, chi=p)\n",
        "    number_of_nodes = count_nodes(tree)\n",
        "    depth = calcualte_max_tree_depth(tree)\n",
        "    trees.extend([tree])\n",
        "    train_accuracies.append(calc_accuracy(tree, X_train))\n",
        "    test_accuracies.append(calc_accuracy(tree, X_test))\n",
        "    tuples.append([p, depth])\n",
        "    print(p, number_of_nodes, depth)\n",
        "\n",
        "\n",
        "best_p_value_index_on_test_data = np.argmax(test_accuracies)\n",
        "tree_chi = trees[best_p_value_index_on_test_data]\n",
        "\n",
        "# print(tree_chi)\n",
        "print(tuples)\n",
        "\n",
        "plt.plot(p_values, train_accuracies, label='Training accuracy')\n",
        "plt.plot(p_values, test_accuracies, label='Test accuracy')\n",
        "plt.scatter(p_values[best_p_value_index_on_test_data], test_accuracies[best_p_value_index_on_test_data], \n",
        "            linewidths=10, color='red', label=f'best test accuracy ({count_nodes(tree_chi)} nodes)')\n",
        "\n",
        "plt.title('Accuracy vs P-value', fontsize=20)\n",
        "plt.xlabel('(p-value, depth)')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.xticks(p_values, [f'({tuples[i][0]}, {tuples[i][1]})' for i in range(len(tuples))], rotation=45)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 3227 10\n",
            "0.5 1906 10\n",
            "0.25 309 9\n",
            "0.1 86 6\n",
            "0.05 45 4\n",
            "0.0001 1 0\n",
            "[[1, 10], [0.5, 10], [0.25, 9], [0.1, 6], [0.05, 4], [0.0001, 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mGLWiQktnFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "561af9eb-3ddd-490a-bf77-792584dda4cc"
      },
      "source": [
        "print(f'Best chi_tree test accuracy: {calc_accuracy(tree_chi, X_test) * 100}%')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best chi_tree test accuracy: 89.51255539143278%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lifvCqCho2x8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lds0_ykrCI9u"
      },
      "source": [
        "## Number of Nodes\n",
        "\n",
        "Of the two trees above we will choose the one with fewer nodes. Complete the function counts_nodes and print the number of nodes in each tree. (5 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U8qB0x1CI9v"
      },
      "source": [
        "# Implemented above as a helper function for the post_pruning function"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpHo0CmxoyxM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtP4j8MRCI9v"
      },
      "source": [
        "## Print the tree\n",
        "\n",
        "Complete the function `print_tree` and execute it on your chosen tree. Your tree should be visualized clearly. You can use the following example as a reference:\n",
        "```\n",
        "[ROOT, feature=X0],\n",
        "  [X0=a, feature=X2]\n",
        "    [X2=c, leaf]: [{1.0: 10}]\n",
        "    [X2=d, leaf]: [{0.0: 10}]\n",
        "  [X0=y, feature=X5], \n",
        "    [X5=a, leaf]: [{1.0: 5}]\n",
        "    [X5=s, leaf]: [{0.0: 10}]\n",
        "  [X0=e, leaf]: [{0.0: 25, 1.0: 50}]\n",
        "```\n",
        "In each brackets:\n",
        "* The first argument is the parent feature with the value that led to current node\n",
        "* The second argument is the selected feature of the current node\n",
        "* If the current node is a leaf, you need to print also the labels and their counts\n",
        "\n",
        "(5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nw1iuvzCI9v"
      },
      "source": [
        "# you can change the function signeture\n",
        "def print_tree(node, depth=0, parent_feature='ROOT', feature_val='ROOT'):\n",
        "    '''\n",
        "    prints the tree according to the example above\n",
        "\n",
        "    Input:\n",
        "    - node: a node in the decision tree\n",
        "\n",
        "    This function has no return value\n",
        "    '''\n",
        "\n",
        "    if node.get_is_leaf():\n",
        "        print(depth *' ' + f'[X{node.parent}={node.feature_name}, leaf]: [{node.class_counts}]')\n",
        "    else:\n",
        "        print(depth *' ' + f'[X{node.parent}={node.feature_name}, feature=X{node.feature}]')\n",
        "\n",
        "        for n in node.children:\n",
        "            print_tree(n, depth + 1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qwLkl_HSJhX",
        "outputId": "5db12fc5-0254-4b29-89fc-3a3ce8044b0c"
      },
      "source": [
        "print_tree(tree_post_pruning)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[X-1=ROOT, feature=X4]\n",
            " [X4=a, leaf]: [{'e': 273, 'p': 31}]\n",
            " [X4=c, leaf]: [{'e': 10, 'p': 137}]\n",
            " [X4=f, leaf]: [{'e': 170, 'p': 1438}]\n",
            " [X4=l, leaf]: [{'e': 272, 'p': 27}]\n",
            " [X4=m, feature=X0]\n",
            "  [X0=f, feature=X2]\n",
            "   [X2=c, feature=X5]\n",
            "    [X5=a, leaf]: [{'p': 2}]\n",
            "    [X5=f, leaf]: [{'e': 1}]\n",
            "   [X2=e, leaf]: [{'p': 4}]\n",
            "   [X2=n, leaf]: [{'p': 2}]\n",
            "  [X0=k, leaf]: [{'e': 1, 'p': 10}]\n",
            "  [X0=x, leaf]: [{'p': 7}]\n",
            " [X4=n, leaf]: [{'e': 2332, 'p': 344}]\n",
            " [X4=p, leaf]: [{'e': 8, 'p': 175}]\n",
            " [X4=s, feature=X13]\n",
            "  [X13=p, feature=X11]\n",
            "   [X11=k, feature=X20]\n",
            "    [X20=d, leaf]: [{'e': 3, 'p': 31}]\n",
            "    [X20=l, leaf]: [{'e': 4, 'p': 30}]\n",
            "    [X20=p, feature=X0]\n",
            "     [X0=f, leaf]: [{'p': 12}]\n",
            "     [X0=k, leaf]: [{'p': 12}]\n",
            "     [X0=x, feature=X1]\n",
            "      [X1=s, leaf]: [{'p': 7}]\n",
            "      [X1=y, feature=X2]\n",
            "       [X2=e, leaf]: [{'p': 3}]\n",
            "       [X2=n, feature=X10]\n",
            "        [X10=k, leaf]: [{'e': 1}]\n",
            "        [X10=s, leaf]: [{'p': 1}]\n",
            "   [X11=s, leaf]: [{'e': 4, 'p': 94}]\n",
            "  [X13=w, feature=X12]\n",
            "   [X12=p, feature=X0]\n",
            "    [X0=f, feature=X1]\n",
            "     [X1=s, leaf]: [{'e': 5, 'p': 15}]\n",
            "     [X1=y, feature=X11]\n",
            "      [X11=k, feature=X2]\n",
            "       [X2=e, leaf]: [{'p': 3}]\n",
            "       [X2=n, feature=X20]\n",
            "        [X20=d, leaf]: [{'e': 1, 'p': 1}]\n",
            "        [X20=l, leaf]: [{'e': 1}]\n",
            "        [X20=p, leaf]: [{'p': 1}]\n",
            "      [X11=s, leaf]: [{'p': 9}]\n",
            "    [X0=k, leaf]: [{'e': 4, 'p': 28}]\n",
            "    [X0=x, feature=X11]\n",
            "     [X11=k, feature=X20]\n",
            "      [X20=d, feature=X2]\n",
            "       [X2=e, feature=X10]\n",
            "        [X10=k, leaf]: [{'p': 1}]\n",
            "        [X10=s, leaf]: [{'e': 1}]\n",
            "       [X2=n, leaf]: [{'p': 1}]\n",
            "      [X20=l, leaf]: [{'p': 7}]\n",
            "      [X20=p, leaf]: [{'p': 5}]\n",
            "     [X11=s, leaf]: [{'e': 6, 'p': 17}]\n",
            "   [X12=w, leaf]: [{'e': 8, 'p': 102}]\n",
            " [X4=y, leaf]: [{'e': 49, 'p': 382}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAylpMJJUgXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834054e3-5d80-4665-cf22-ff0cd7ac3c04"
      },
      "source": [
        "print_tree(tree_chi)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[X-1=ROOT, feature=X4]\n",
            " [X4=a, leaf]: [{'e': 273, 'p': 31}]\n",
            " [X4=c, leaf]: [{'e': 10, 'p': 137}]\n",
            " [X4=f, leaf]: [{'e': 170, 'p': 1438}]\n",
            " [X4=l, feature=X1]\n",
            "  [X1=f, leaf]: [{'e': 19, 'p': 1}]\n",
            "  [X1=s, leaf]: [{'e': 94, 'p': 16}]\n",
            "  [X1=y, leaf]: [{'e': 159, 'p': 10}]\n",
            " [X4=m, leaf]: [{'e': 2, 'p': 25}]\n",
            " [X4=n, feature=X18]\n",
            "  [X18=b, leaf]: [{'e': 34, 'p': 2}]\n",
            "  [X18=h, feature=X2]\n",
            "   [X2=r, leaf]: [{'e': 9, 'p': 4}]\n",
            "   [X2=u, leaf]: [{'e': 14}]\n",
            "   [X2=w, leaf]: [{'e': 12, 'p': 1}]\n",
            "  [X18=k, leaf]: [{'e': 875, 'p': 96}]\n",
            "  [X18=n, feature=X8]\n",
            "   [X8=g, leaf]: [{'e': 9, 'p': 1}]\n",
            "   [X8=h, leaf]: [{'e': 68, 'p': 8}]\n",
            "   [X8=k, leaf]: [{'e': 79, 'p': 7}]\n",
            "   [X8=n, leaf]: [{'e': 236, 'p': 24}]\n",
            "   [X8=o, leaf]: [{'e': 12}]\n",
            "   [X8=p, feature=X2]\n",
            "    [X2=e, leaf]: [{'e': 45, 'p': 4}]\n",
            "    [X2=g, feature=X1]\n",
            "     [X1=f, leaf]: [{'e': 47}]\n",
            "     [X1=s, feature=X10]\n",
            "      [X10=f, leaf]: [{'e': 6}]\n",
            "      [X10=s, leaf]: [{'e': 2, 'p': 2}]\n",
            "     [X1=y, feature=X13]\n",
            "      [X13=g, leaf]: [{'e': 10}]\n",
            "      [X13=p, leaf]: [{'e': 6, 'p': 2}]\n",
            "      [X13=w, leaf]: [{'e': 9}]\n",
            "    [X2=n, leaf]: [{'e': 79, 'p': 6}]\n",
            "    [X2=w, leaf]: [{'e': 20, 'p': 5}]\n",
            "   [X8=u, leaf]: [{'e': 138, 'p': 21}]\n",
            "   [X8=w, feature=X12]\n",
            "    [X12=g, feature=X0]\n",
            "     [X0=f, leaf]: [{'e': 20, 'p': 8}]\n",
            "     [X0=x, leaf]: [{'e': 26, 'p': 2}]\n",
            "    [X12=p, leaf]: [{'e': 53, 'p': 4}]\n",
            "    [X12=w, feature=X13]\n",
            "     [X13=g, leaf]: [{'e': 19}]\n",
            "     [X13=p, leaf]: [{'e': 11, 'p': 4}]\n",
            "     [X13=w, leaf]: [{'e': 11, 'p': 8}]\n",
            "   [X8=y, leaf]: [{'e': 10, 'p': 4}]\n",
            "  [X18=o, feature=X19]\n",
            "   [X19=c, leaf]: [{'e': 12, 'p': 4}]\n",
            "   [X19=v, leaf]: [{'e': 16}]\n",
            "  [X18=r, leaf]: [{'e': 6, 'p': 46}]\n",
            "  [X18=w, feature=X20]\n",
            "   [X20=d, feature=X7]\n",
            "    [X7=b, leaf]: [{'e': 6, 'p': 2}]\n",
            "    [X7=n, leaf]: [{'p': 25}]\n",
            "   [X20=g, leaf]: [{'e': 204, 'p': 19}]\n",
            "   [X20=l, feature=X2]\n",
            "    [X2=c, leaf]: [{'e': 19, 'p': 1}]\n",
            "    [X2=n, leaf]: [{'e': 15, 'p': 4}]\n",
            "    [X2=w, leaf]: [{'p': 8}]\n",
            "    [X2=y, leaf]: [{'p': 7}]\n",
            "   [X20=p, leaf]: [{'e': 29, 'p': 1}]\n",
            "   [X20=w, feature=X13]\n",
            "    [X13=e, feature=X0]\n",
            "     [X0=f, leaf]: [{'e': 18, 'p': 5}]\n",
            "     [X0=k, leaf]: [{'e': 21}]\n",
            "     [X0=x, feature=X8]\n",
            "      [X8=e, leaf]: [{'e': 9, 'p': 4}]\n",
            "      [X8=w, leaf]: [{'e': 14}]\n",
            "    [X13=w, leaf]: [{'e': 68, 'p': 2}]\n",
            "  [X18=y, leaf]: [{'e': 35, 'p': 3}]\n",
            " [X4=p, feature=X0]\n",
            "  [X0=f, feature=X18]\n",
            "   [X18=k, leaf]: [{'e': 6, 'p': 43}]\n",
            "   [X18=n, leaf]: [{'e': 1, 'p': 43}]\n",
            "  [X0=x, leaf]: [{'e': 1, 'p': 89}]\n",
            " [X4=s, feature=X13]\n",
            "  [X13=p, leaf]: [{'e': 12, 'p': 190}]\n",
            "  [X13=w, feature=X12]\n",
            "   [X12=p, leaf]: [{'e': 18, 'p': 88}]\n",
            "   [X12=w, feature=X0]\n",
            "    [X0=f, leaf]: [{'p': 38}]\n",
            "    [X0=k, leaf]: [{'e': 3, 'p': 30}]\n",
            "    [X0=x, leaf]: [{'e': 5, 'p': 34}]\n",
            " [X4=y, feature=X1]\n",
            "  [X1=s, leaf]: [{'e': 18, 'p': 194}]\n",
            "  [X1=y, leaf]: [{'e': 31, 'p': 188}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oib5D2WfogEd"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    }
  ]
}